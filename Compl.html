<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Teoria della Complessità</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="style/style.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body);
  });</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header>
<h1 class="title">Teoria della Complessità</h1>
</header>
<h1 id="introduzione">Introduzione</h1>
<p>Ramo dell’Informatica Teorica focalizzato sulla <strong>classificazione</strong> dei problemi computazionali in funzione della loro inerente difficoltà, ovvero delle <em>risorse necessarie alla loro risoluzione</em>.</p>
<p>Richiede una definizione precisa di un modello di calcolo che permetta la quantificazione delle risorse (ad esempio tempo e spazio) necessarie alla computazione.</p>
<h2 id="notazioni-utilizzate">Notazioni Utilizzate</h2>
<ul>
<li><span class="math inline">\(bin(n)\)</span> per la rappresentazione binaria del naturale <span class="math inline">\(n\)</span></li>
<li><p><span class="math inline">\(log(n) \coloneqq |bin(n)| - 1 = \log_2({max(1,n)})\)</span></p></li>
<li><p>Sia <span class="math inline">\(f \colon N \rightarrow N\)</span>:</p>
<ul>
<li><span class="math inline">\(O(f)\)</span> è la classe delle funzioni che crescono <strong>al più</strong> come <span class="math inline">\(f\)</span>,</li>
<li><span class="math inline">\(o(f)\)</span> è la classe delle funzioni che crescono <strong>meno rapidamente</strong> di <span class="math inline">\(f\)</span>,</li>
<li><span class="math inline">\(\Omega(f)\)</span> è la classe delle funzioni che crescono <strong>almeno quanto</strong> <span class="math inline">\(f\)</span>,</li>
<li><span class="math inline">\(\Theta(f)\)</span> è la classe delle funzioni che crescono <strong>esattamente come</strong> <span class="math inline">\(f\)</span>.</li>
</ul></li>
</ul>
<h2 id="grafi---definizioni">Grafi - Definizioni</h2>
<p>Un grafo finito è una coppia <span class="math inline">\((V, E)\)</span> dove:</p>
<ul>
<li><span class="math inline">\(V\)</span> è un insieme finito di vertici,</li>
<li><span class="math inline">\(E \subseteq (V \times V)\)</span> è una relazione che definisce l’insieme degli archi.</li>
</ul>
<p>Un grafo si dice non orientato quando la relazione <span class="math inline">\(E\)</span> è <strong>simmetrica</strong> e <strong>irriflessiva</strong>.</p>
<p>Sia <span class="math inline">\(G = (V, E)\)</span> un grafo:</p>
<ul>
<li>due vertici <span class="math inline">\(u, v \in V\)</span> sono <strong>adiacenti</strong> se esiste un arco <span class="math inline">\((u, v) \in E\)</span>.</li>
<li>un cammino è una <strong>sequenza di vertici</strong> dove tutte le coppie di vertici consecutivi sono adiacenti.</li>
<li>un cammino è <strong>semplice</strong> se tutti i vertici sono <em>distinti</em>.</li>
<li>un <strong>ciclo</strong> è un cammino semplice il cui <em>ultimo vertice è adiacente al primo</em>.</li>
<li><p>un cammino (o un ciclo) <strong>Hamiltoniano</strong> in <span class="math inline">\(G\)</span> è un cammino (o un ciclo) che comprende <strong>tutti</strong> i vertici del grafo.</p>
<figure>
<img src="img/Hamiltoniano.png" title="Cammino Hamiltoniano" alt="Esempio di cammino Hamiltoniano" /><figcaption>Esempio di cammino Hamiltoniano</figcaption>
</figure></li>
<li><p>un <strong>ricoprimento di vertici</strong> per <span class="math inline">\(G\)</span> è un sottoinsieme <span class="math inline">\(V_0 \subseteq V\)</span> tale che ogni arco <span class="math inline">\(e \in E\)</span> ha almeno una estremità in <span class="math inline">\(V_0\)</span>.</p>
<figure>
<img src="img/Ricoprimento.png" title="Ricoprimento" alt="Esempio di ricoprimento di vertici" /><figcaption>Esempio di ricoprimento di vertici</figcaption>
</figure>
<p>Si noti che <span class="math inline">\(V\)</span> è un <em>caso degenere</em> di ricoprimento. Inoltre se <span class="math inline">\(R\)</span> è un ricoprimento, ogni suo <strong>soprainsieme</strong> lo è. Siamo interessati a trovare <strong>ricoprimenti minimi</strong>.</p></li>
<li><p><span class="math inline">\(G\)</span> è <strong><span class="math inline">\(n\)</span>-colorabile</strong>, se esiste una funzione di colorazione <span class="math inline">\(col \colon V \rightarrow c_1 , \dots , c_n\)</span> tale che vertici <em>adiacenti</em> hanno <strong>colori diversi</strong>, ovvero:</p>
<p><span class="math display">\[(u, v) \in E \rightarrow col(u) \not = col(v )\]</span></p></li>
<li><p><span class="math inline">\(G\)</span> è <strong>completo</strong> se ogni coppia di nodi distinti è <strong>connessa da un arco</strong>.</p></li>
<li><p>una <strong>cricca</strong> (clique) di <span class="math inline">\(G\)</span> è un suo sottografo <em>completo</em> <span class="math inline">\(G&#39; = (V&#39;, E&#39;)\)</span>, ovvero <span class="math inline">\(V&#39; \subseteq V\)</span> ed <span class="math inline">\(E&#39; = V&#39; \times V&#39; \subseteq E\)</span>.</p>
<figure>
<img src="img/Cricca.png" title="Cricca" alt="Esempio di cricca di un grafo" /><figcaption>Esempio di cricca di un grafo</figcaption>
</figure>
<p>Per ogni <span class="math inline">\(v \in V\)</span>, <span class="math inline">\(\{v\}\)</span> è un <em>caso degenere</em> di cricca (come anche l’insieme vuoto). Ogni <strong>coppia di nodi <span class="math inline">\(\{u, v\}\)</span> connessi da un arco</strong> forma una cricca.Ogni sottoinsieme di una cricca è ancora una cricca. Siamo interessati a trovare cricche massime.</p></li>
<li><p>un <strong>insieme indipendente</strong> in <span class="math inline">\(G\)</span> è un sottoinsieme di vertici <span class="math inline">\(V&#39; \subseteq V\)</span> tale che per ogni coppia di vertici <span class="math inline">\(u, v \in V&#39; \rightarrow (u, v) \not \in E\)</span>.</p>
<figure>
<img src="img/Indipendente.png" title="Insieme indipendente" alt="Esempio di insieme indipendente" /><figcaption>Esempio di insieme indipendente</figcaption>
</figure>
<p>Per ogni <span class="math inline">\(v \in V\)</span>, <span class="math inline">\(\{v\}\)</span> è un <em>caso degenere</em> di insieme indipendente (come anche l’insieme vuoto). Ogni <strong>sottoinsieme</strong> di un insieme indipendente è ancora indipendente. Siamo interessati a trovare <strong>insiemi indipendenti massimi</strong>.</p></li>
</ul>
<h2 id="flusso-massimo">Flusso massimo</h2>
<p>Una rete <span class="math inline">\(N\)</span> è un grafo <em>orientato</em> con una sorgente <span class="math inline">\(s\)</span>, un pozzo <span class="math inline">\(t\)</span>, e una capacità <span class="math inline">\(c(u, v)\)</span> associata ad ogni arco.</p>
<figure>
<img src="img/Rete.png" title="Rete di flusso" alt="Esempio di problema di flusso" /><figcaption>Esempio di problema di flusso</figcaption>
</figure>
<p>Un flusso in <span class="math inline">\(N\)</span> è una funzione <span class="math inline">\(f(u, v)\)</span> che ad ogni arco <span class="math inline">\((u, v)\)</span> associa un intero positivo tale che:</p>
<ul>
<li><span class="math inline">\(f(u, v) \le c(u, v)\)</span></li>
<li>la somma dei flussi entranti in ogni nodo (a parte <span class="math inline">\(s\)</span> e <span class="math inline">\(t\)</span>) deve essere uguale alla somma dei flussi uscenti.</li>
</ul>
<p>Il problema consiste nel determinare il <strong>flusso massimo</strong> dalla sorgente al pozzo.</p>
<h3 id="algoritmo">Algoritmo</h3>
<ol type="1">
<li>Si parte con un flusso <strong>maxf</strong> inizialmente nullo.</li>
<li>Si cerca un cammino da <span class="math inline">\(s\)</span> a <span class="math inline">\(t\)</span> nella rete <span class="math inline">\(N\)</span> e si considera il flusso <span class="math inline">\(f\)</span> lungo tale cammino determinato dalla <strong>capacità massima</strong> dei sui archi; se tale cammino non esiste si restituisce <strong>maxf</strong>.</li>
<li>Si pone <strong>maxf</strong> <span class="math inline">\(\coloneqq\)</span> <strong>maxf</strong> $ + f; N N f$ e si ripete dal passo 2.</li>
</ol>
<h3 id="complessità-mf">Complessità MF</h3>
<p>Osserviamo innanzitutto che se <span class="math inline">\(C\)</span> è la <em>massima capacità</em> degli archi, il flusso massimo è <strong>sicuramente inferiore</strong> a <span class="math inline">\(nC\)</span> in quanto ci sono meno di <span class="math inline">\(n\)</span> archi che partono dalla sorgente.</p>
<ul>
<li>la ricerca del cammino costa <span class="math inline">\(O(n^2)\)</span> il flusso aumenta ad ogni iterazione del ciclo; dunque viene ripetuto al più <span class="math inline">\(nC\)</span> volte.</li>
</ul>
<p>In conclusione, la complessità è <strong><span class="math inline">\(O(n^3C)\)</span></strong>.</p>
<p>L’algoritmo del <em>flusso massimo</em> dipende in modo lineare da <span class="math inline">\(C\)</span>, e dunque potrebbe dipendere in modo <em>esponenziale</em> dalla descrizione della capacità degli archi della rete.</p>
<figure>
<img src="img/Pessimo.png" title="Caso pessimo" alt="Esempio di caso pessimo per il problema di flusso" /><figcaption>Esempio di caso pessimo per il problema di flusso</figcaption>
</figure>
<p>È possibile ovviare al problema selezionando ad ogni iterazione il cammino più corto da <span class="math inline">\(s\)</span> a <span class="math inline">\(t\)</span>. Questo fa si che un arco risulterà essere un <strong>collo di bottiglia</strong> (arco su di un cammino da <span class="math inline">\(s\)</span> a <span class="math inline">\(t\)</span> con capacità <strong>minima</strong>) in un numero limitato di casi, permettendo di maggiorare il numero di iterazioni con <span class="math inline">\(n^3\)</span>. Dunque la complessità dell’algoritmo è <span class="math inline">\(O(n^5)\)</span>.</p>
<p><strong>NB 1:</strong> La distanza di un nodo <span class="math inline">\(u\)</span> da <span class="math inline">\(s\)</span> non può decrementare passando da <span class="math inline">\(N\)</span> a <span class="math inline">\(N \setminus f\)</span>: <span class="math inline">\(d_{N \setminus f}(u) \ge d_{N}(u)\)</span>.</p>
<p><strong>NB 2:</strong> Se l’arco <span class="math inline">\((u, v)\)</span> è il <em>collo di bottiglia</em> del flusso <span class="math inline">\(f\)</span> allora se <span class="math inline">\((u, v)\)</span> verrà mai attraversato nuovamente da un flusso successivo <span class="math inline">\(f&#39;\)</span> (<strong>necessariamente</strong> nella direzione opposta) la distanza <span class="math inline">\(d_{N&#39;}(u)\)</span> di <span class="math inline">\(u\)</span> da <span class="math inline">\(s\)</span> sarà aumentata.</p>
<p>Infatti, <span class="math inline">\(d_{N&#39;}(u) \gt d_{N&#39;}(v ) \ge d_N(v)\)</span>; se <span class="math inline">\(d_{N&#39;}(u) = d_{N}(u)\)</span> avremmo <span class="math inline">\(d_{N}(u) \gt d_{N}(v)\)</span> contraddicendo la minimalità di <span class="math inline">\(f\)</span>.</p>
<figure>
<img src="img/Collodb.png" title="Collo di bottiglia" alt="Esempio di collo di bottiglia per il problema di flusso" /><figcaption>Esempio di collo di bottiglia per il problema di flusso</figcaption>
</figure>
<p>Le distanze sono maggiorate dal numero dei nodi, dunque ogni ogni arco può essere un collo di bottiglia <strong>al più <span class="math inline">\(n\)</span> volte</strong>, e il numero dei flussi è al più <span class="math inline">\(O(n \cdot |E|) \le O(n^3)\)</span>.</p>
<h2 id="problemi-decisionali">Problemi decisionali</h2>
<p>La <em>2-colorazione</em> e la <em>raggiungibilità</em> sono esempi di problemi di <strong>decisione</strong>, cioè problemi che richiedono una risposta <strong>booleana</strong> (definiscono dunque un <strong>linguaggio</strong>).</p>
<p>Il problema del <em>flusso massimo</em> è un tipico esempio di problema di <strong>ottimizzazione</strong>, cioè un problema che richiede la scelta della <em>migliore</em> soluzione tra un insieme di risposte ammissibili rispetto ad una data funzione di costo.</p>
<p>È possibile fornire una versione <strong>decisionale</strong> di un problema di <strong>ottimizzazione</strong>, semplicemente chiedendo se esiste una soluzione <strong>non peggiore</strong> di un valore prefissato. Spesso i due problemi hanno complessità comparabili (è possibile determinare la complessità dell’uno in funzione dell’altro).</p>
<h2 id="matching-bipartito">Matching bipartito</h2>
<p>Un <strong>grafo bipartito</strong> è una tripla <span class="math inline">\(B = (U, V , E)\)</span> dove <span class="math inline">\(U\)</span> e <span class="math inline">\(V\)</span> sono due insiemi di nodi di <em>uguale cardinalità</em> e <span class="math inline">\(E \subseteq U \times V\)</span> è un insieme di archi.</p>
<p>Un <strong>matching</strong> è un insieme <span class="math inline">\(M \subseteq E\)</span> che associa ad ogni elemento in <span class="math inline">\(U\)</span> uno e un solo elemento in <span class="math inline">\(V\)</span>.</p>
<figure>
<img src="img/Matching.png" title="Matching bipartito" alt="Esempio di matching bipartito" /><figcaption>Esempio di matching bipartito</figcaption>
</figure>
<p>Il problema consiste nel determinare l’esistenza o meno di un matching.</p>
<h3 id="riduzione-ad-un-problema-noto">Riduzione ad un problema noto</h3>
<p><strong>Riduciamo</strong> il problema ad un problema di flusso, orientando gli archi da <span class="math inline">\(U\)</span> a <span class="math inline">\(V\)</span>, aggiungendo una sorgente <span class="math inline">\(s\)</span>, un pozzo <span class="math inline">\(t\)</span>, un arco <span class="math inline">\((s, u)\)</span>, <span class="math inline">\(\forall u \in U\)</span> e un arco <span class="math inline">\((v, t)\)</span>, <span class="math inline">\(\forall v \in V\)</span>. Tutti gli archi hanno capacità <strong>unitaria</strong>.</p>
<p>È facile vedere che il grafo bipartito <strong>ammette un matching</strong> se e solo se la rete così ottenuta ammette un <strong>flusso di entità <span class="math inline">\(n\)</span></strong>, dove <span class="math inline">\(n = |U| = |V|\)</span>.</p>
<figure>
<img src="img/Riduzione.png" title="Riduzione" alt="Esempio di un matching bipartito ad un problema di flusso" /><figcaption>Esempio di un matching bipartito ad un problema di flusso</figcaption>
</figure>
<p>Poichè la rete può essere costruita in tempo <em><strong>lineare</strong> nella dimensione del grafo</em>, il problema del matching in un grafo bipartito è <span class="math inline">\(O(n^3)\)</span> (si conoscono soluzioni migliori).</p>
<h2 id="insieme-indipendente-ricoprimento-e-cricca">Insieme indipendente, ricoprimento e cricca</h2>
<p>Dato un grafo <span class="math inline">\(G = (V , E)\)</span> e un intero <span class="math inline">\(k\)</span> determinare se:</p>
<ol type="1">
<li>esiste un insieme <em>indipendente</em> <span class="math inline">\(V&#39; \subseteq V\)</span> tale che <span class="math inline">\(k \le |V&#39;|\)</span>;</li>
<li>esiste un <em>ricoprimento</em> <span class="math inline">\(V&#39; \subseteq V\)</span> tale che <span class="math inline">\(|V&#39;| \le k\)</span>;</li>
<li>esiste una <em>cricca</em> <span class="math inline">\(V&#39; \subseteq V\)</span> tale che <span class="math inline">\(k \le |V&#39;|\)</span>;</li>
</ol>
<p>Questi tre problemi sono riducibili l’uno all’altro. Ricordiamo le definizioni:</p>
<ul>
<li><p>un insieme <span class="math inline">\(V&#39; \subseteq V\)</span> è detto <strong>indipendente</strong> se</p>
<span class="math display">\[\forall u, v \in V&#39; \rightarrow (u, v ) \not \in E\]</span></li>
<li><p>un sottoinsieme <span class="math inline">\(V&#39; \subseteq V\)</span> è detto <strong>ricoprimento</strong> se</p>
<span class="math display">\[\forall (u, v) \in E, u \in V&#39; \lor  v \in V&#39;\]</span></li>
<li><p>una <strong>cricca</strong> di <span class="math inline">\(G\)</span> è un sottoinsieme completo <span class="math inline">\(V&#39; \subseteq V\)</span>, tale cioè che</p>
<p><span class="math display">\[\forall u, v \in V&#39; \rightarrow (u, v) \in E\]</span></p></li>
</ul>
<p>È facile vedere che:</p>
<ul>
<li><span class="math inline">\(V&#39; \subseteq V\)</span> è <strong>indipendente</strong> se e solo se <span class="math inline">\(V \setminus V&#39;\)</span> è un <strong>ricoprimento</strong>;</li>
<li><span class="math inline">\(V&#39; \subseteq V\)</span> è <strong>indipendente</strong> se e solo se <span class="math inline">\(V&#39;\)</span> è una <strong>cricca</strong> nel grafo <span class="math inline">\(G&#39; = (V, \overline{E})\)</span></li>
</ul>
<h2 id="ricerca-vs.verifica">Ricerca vs. Verifica</h2>
<p><strong>Cercare</strong> in modo esaustivo un insieme indipendente (un ricoprimento, o una cricca) di cardinalità <span class="math inline">\(k\)</span> richiede l’esame di un numero di casi pari a <span class="math display">\[\frac{n!}{k!(n - k)!}\]</span></p>
<p>Per valori di <span class="math inline">\(k \approx \frac{n}{2}\)</span> questa quantità cresce in modo <strong>esponenziale</strong> in <span class="math inline">\(k\)</span>.</p>
<p>Non è noto se sia possibile avere algoritmi <strong>polinomiali</strong> per risolvere questi problemi (di ricerca).</p>
<p>Al contrario, <strong>verificare</strong> se un sottoinsieme dato di vertici è indipendente (un ricoprimento, o una cricca) richiede un tempo <strong>polinomiale</strong> nel numero dei vertici.</p>
<p>I problemi che ammettono soluzioni polinomiali nella dimensione dell’input e algoritmi polinomiali di <strong>verifica della correttezza</strong> di tali soluzioni sono detti problemi <strong>NP</strong>.</p>
<h3 id="soddisfacibilità">Soddisfacibilità</h3>
<p>Data una formula proposizionale, <strong>determinare</strong> (cercare) se è soddisfacibile, cioè se esiste una attribuzione di valori di verità alle variabili proposizionali (funzione di valutazione) che rende vera la formula.</p>
<p>Esempio:</p>
<ul>
<li><span class="math inline">\((P \rightarrow Q) \land \lnot P \land Q\)</span> è <em>soddisfacibile</em> <span class="math inline">\((P = 0, Q = 1)\)</span></li>
<li><span class="math inline">\((Q \rightarrow P) \land \lnot P \land Q\)</span> è <em>insoddisfacibile</em></li>
</ul>
<p>Il numero totale di funzioni di valutazione è <span class="math inline">\(2^n\)</span> (e quindi <strong>esponenziale</strong>) dove <span class="math inline">\(n\)</span> è il numero di variabili proposizionali nella formula.</p>
<p>Esistono procedimenti migliori (e.g. risoluzione), ma <strong>non</strong> si conoscono algoritmi <em>polinomiali</em>.</p>
<p><strong>Verificare</strong> che una data funzione di valutazione rende vera la formula ha un costo <em>lineare</em> nella dimensione della formula.</p>
<h3 id="commesso-viaggiatore">Commesso viaggiatore</h3>
<p>Sono date <span class="math inline">\(n\)</span> città e una distanza intera <span class="math inline">\(d_{ij} = d_{ji} \gt 0\)</span> tra ciascuna esse. Il problema consiste nel determinare il ciclo di <strong>lunghezza minima</strong>, ovvero una permutazione <span class="math inline">\(\pi\)</span> tale che la quantità</p>
<p><span class="math display">\[d_{\pi} = \sum\limits_{i=1}^n d_{\pi(i),\pi(i+1)}\]</span></p>
<p>sia <strong>minima</strong>.</p>
<p>La versione <strong>decisionale</strong> consite nel determinare se esiste un ciclo di lunghezza inferiore o uguale ad una distanza data <span class="math inline">\(d\)</span>.</p>
<p>Il numero complessivo delle permutazioni è <span class="math inline">\(\frac{(n-1)!}{2}\)</span>. È possibile migliorare il bound (ad un “semplice” esponenziale) con tecniche di <em>programmazione dinamica</em>, ma non si conoscono algoritmi <strong>polinomiali</strong>.</p>
<p>D’altra parte, <strong>verificare</strong> che un dato cammino <span class="math inline">\(\pi\)</span> ha una lunghezza <span class="math inline">\(d_{\pi} \le d\)</span> richiede un tempo <strong>lineare</strong> in <span class="math inline">\(n\)</span>.</p>
<h3 id="knapsak">Knapsak</h3>
<p>Dato uno zaino di volume <span class="math inline">\(V\)</span> e <span class="math inline">\(n\)</span> oggetti <span class="math inline">\(O = \{1,\dots, n\}\)</span> ciascuno con un volume <span class="math inline">\(v(i)\)</span> (con <span class="math inline">\(V\)</span> , <span class="math inline">\(v_i\)</span> interi positivi), determinare se esiste un sottoinsieme <span class="math inline">\(I \subseteq O\)</span> tale che</p>
<p><span class="math display">\[V = \sum\limits_{i \in I} v(i)\]</span></p>
<p>Ad esempio, dati 7 oggetti di volume <span class="math inline">\(\{6, 7, 8, 9, 10, 11, 13\}\)</span> è possibile riempire uno zaino di dimensione <span class="math inline">\(V = 52\)</span>?</p>
<p>Una <strong>ricerca</strong> esaustiva impone di considerare tutti i sottoinsiemi, ovvero <span class="math inline">\(2^n\)</span> (e.g. <strong>esponenziale</strong>) casi.</p>
<p>Anche in questo caso, <strong>verificare</strong> che un dato sottoinsieme rispetta la condizione voluta richiede un costo <strong>al più lineare</strong> nel numero degli oggetti.</p>
<h2 id="riassumendo">Riassumendo</h2>
<ul>
<li><p>La classe <span class="math inline">\(P\)</span> è la classe dei problemi che ammettono un algoritmo rapido di <strong>ricerca</strong> della soluzione</p></li>
<li><p>La classe <span class="math inline">\(NP\)</span> è la classe dei problemi che ammettono un algoritmo rapido di <strong>verifica</strong> della correttezza soluzione</p></li>
</ul>
<h1 id="classi-deterministiche-di-complessità">Classi deterministiche di complessità</h1>
<h2 id="la-macchina-di-turing">La Macchina di Turing</h2>
<h3 id="hardware">Hardware</h3>
<ul>
<li>nastri di memoria <strong>illimitati</strong>, divisi in celle di dimensione <strong>fissata</strong>. Ogni cella può contenere un <strong>carattere</strong> di un <em>alfabeto</em> dato, compreso un carattere <span class="math inline">\(b\)</span> (bianco) di inizializzazione.</li>
<li>una <em>testina</em> di lettura mobile per ogni nastro.</li>
<li>un <em>automa</em> di controllo a stati <strong>finiti</strong>.</li>
</ul>
<figure>
<img src="img/Turing.png" title="Macchina di Turing" alt="Esempio di macchina di Turing" /><figcaption>Esempio di macchina di Turing</figcaption>
</figure>
<h3 id="operazioni-elementari">Operazioni elementari</h3>
<ul>
<li><strong>leggere</strong> e <strong>scrivere</strong> il carattere individuato dalla testina (il nastro di input è di <em>sola lettura</em>, quello di output di <em>sola scrittura</em>)</li>
<li><strong>spostare</strong> la testina di una posizione verso destra o verso sinistra sul <em>nastro di lavoro</em> (sui nastri di input/output la testina può solo muoversi verso destra)</li>
<li><strong>modificare</strong> lo stato interno dell’automa</li>
</ul>
<h2 id="definizione-formale">Definizione formale</h2>
<p>Una <strong>Macchina di Turing</strong> (multi-tape, deterministica) è una tupla <span class="math inline">\(\langle Q, \Gamma, b, \Sigma, k, \delta, q_{0}, F\rangle\)</span> dove:</p>
<ul>
<li><span class="math inline">\(Q\)</span> è un insieme finito di <strong>stati</strong></li>
<li><span class="math inline">\(\Gamma\)</span> è l’ <strong>alfabeto finito</strong> del nastro</li>
<li><span class="math inline">\(b \in \Gamma\)</span> è il <strong>carattere bianco</strong></li>
<li><span class="math inline">\(\Sigma \subseteq \Gamma \setminus \{b\}\)</span> è l’insieme dei <strong>caratteri di input/output</strong></li>
<li><span class="math inline">\(k \ge 1\)</span> è il <strong>numero</strong> degi nastri</li>
<li><span class="math inline">\(q_0 \in Q\)</span> è lo <strong>stato iniziale</strong></li>
<li><span class="math inline">\(F \subseteq Q\)</span> è l’insieme degli <strong>stati finali</strong></li>
<li><span class="math inline">\(\delta : (Q \setminus F) \times \Gamma^k \rightarrow Q \times \Gamma^k \times \{L, R\}^k\)</span> è la <strong>funzione di transizione</strong></li>
</ul>
<p><span class="math inline">\(L\)</span> e <span class="math inline">\(R\)</span> denotano le possibili mosse della testina.</p>
<h2 id="convenzioni-di-inputoutput">Convenzioni di input/output</h2>
<ul>
<li><p><strong>Input</strong>: si suppone che il nastro di input sia inizializzato con la stringa di input (un carattere per ogni cella); la testina è posizionata sul primo carattere dell’input; tutte le altre celle del nastro sono inizializzate col carattere speciale <span class="math inline">\(b\)</span>.</p></li>
<li><p><strong>Output</strong>: nel momento in cui la macchina si arresta l’output è la più <em>lunga stringa di caratteri</em> in <span class="math inline">\(\Sigma\)</span> (in particolare, senza <span class="math inline">\(b\)</span>) alla sinistra della testina sul nastro di output.</p></li>
<li><p><strong>Nastri</strong>: se <span class="math inline">\(k \gt 1\)</span> il nastro <span class="math inline">\(1\)</span> è un nastro di sola lettura (input); se <span class="math inline">\(k \gt 2\)</span> il nastro <span class="math inline">\(k\)</span> è un nastro di sola scrittura (output)</p></li>
<li><p><strong>Spostamenti</strong>: le sole mosse consentite sui nastri di input/output sono spostamenti verso destra.</p></li>
</ul>
<h2 id="configurazioni-istantanee">Configurazioni istantanee</h2>
<p>Una <strong>configurazione</strong> è una descrizione dello <strong>stato</strong> della computazione ad un dato <strong>istante</strong> della computazione. Questa è definita come una tupla</p>
<p><span class="math display">\[(q, (\sigma_1,\tau_1),\dots,(\sigma_k,\tau_k))\]</span></p>
<p>dove <span class="math inline">\(q\)</span> è lo <strong>stato</strong> dell’automa e <span class="math inline">\(\sigma_i, \tau_i\)</span> sono due stringhe di caratteri che descrivono <strong>la porzione non bianca</strong> del nastro <span class="math inline">\(i\)</span> alla sinistra e alla destra della relativa testina. Il carattere in lettura è il primo carattere di <span class="math inline">\(\tau_i\)</span>.</p>
<p>La computazione avviene per <strong>passi discreti</strong>: una transizione tra due configurazioni è una relazione <span class="math inline">\(\vdash\)</span> governata dalla funzione di transizione:</p>
<p><span class="math display">\[(q,(\sigma_{1}b_{1},a_{1}\tau_{1}),\dots,(\sigma_{k}b_{k},a_{k}\tau_{k})) \vdash ((\sigma_{1}\beta_{1},\alpha_{1}\tau_{1}),\dots,(\sigma_{k}\beta_{k},\alpha_{k}\tau_{k}))\]</span></p>
<p>se <span class="math inline">\(\delta(q,a_1,\dots,a_k) = (q&#39;,a&#39;_1,\dots,a&#39;_k,D_1,\dots,D_k)\)</span>, ovvero se il risultato della <em>funzione di transizione</em> chiamata sulla tupla contenente lo <strong>stato attuale</strong> (<span class="math inline">\(q\)</span>) e la <strong>stringa contenuta</strong> nell’<span class="math inline">\(i\)</span>-esimo nastro (<span class="math inline">\(a_1,\dots,a_k\)</span>) è pari alla tupla contenente il <strong>nuovo stato</strong> (<span class="math inline">\(q&#39;\)</span>), la <strong>stringa da scrivere</strong> sull’<span class="math inline">\(i\)</span>-esimo nastro (<span class="math inline">\(a&#39;_1,\dots,a&#39;_k)\)</span>.</p>
<ul>
<li>se <span class="math inline">\(D_i = R\)</span> allora <span class="math inline">\(\beta_i = b_{i}a&#39;_i\)</span> e <span class="math inline">\(\alpha_i = \epsilon\)</span>, ovvero se la direzione è <span class="math inline">\(R\)</span> allora la testina si muove verso <strong>destra</strong> scrivendo <span class="math inline">\(b_{i}a&#39;_i\)</span> sull’<span class="math inline">\(i\)</span>-esimo nastro.</li>
<li>se <span class="math inline">\(D_i = L\)</span> allora <span class="math inline">\(\beta_i = \epsilon\)</span> e <span class="math inline">\(\gamma_i = b_{i}a&#39;_i\)</span>, ovvero se la direzione è <span class="math inline">\(L\)</span> allora la testina si muove verso <strong>sinistra</strong> scrivendo <span class="math inline">\(b_{i}a&#39;_i\)</span> sull’<span class="math inline">\(i\)</span>-esimo nastro.</li>
</ul>
<p>Il nastro può essere esteso “on demand” con caratteri bianchi se necessario.</p>
<h2 id="computazioni">Computazioni</h2>
<p>La relazione <span class="math inline">\(\vdash^*\)</span> denota la <strong>chiusura transitiva e riflessiva</strong> della relazione <span class="math inline">\(\vdash\)</span>.</p>
<p>Una funzione <span class="math inline">\(f: \Sigma^* \rightarrow \Sigma^*\)</span> è calcolata da una macchina di Turing <span class="math inline">\(M\)</span> se per ogni <span class="math inline">\(\alpha\)</span> esiste <span class="math inline">\(q_f \in F\)</span> tale che</p>
<p><span class="math display">\[( q_0, (\epsilon, \alpha), \dots, (\epsilon, \epsilon)) \vdash^* (q_f,(\gamma_1,\tau_1), \dots,(\gamma_k, \tau_k))\]</span></p>
<p>e <span class="math inline">\(f(\alpha)\)</span> è il <strong>più lungo suffisso</strong> di <span class="math inline">\(\gamma_k\)</span> appartenente a <span class="math inline">\(\Sigma^*\)</span>.</p>
<h2 id="classi-deterministiche-di-complessità-1">Classi deterministiche di Complessità</h2>
<p>Una <em>classe di complessità</em> è un insieme di funzioni che possono essere calcolate con delle date risorse. Presteremo speciale attenzione alle funzioni Booleane, in particolare quelle che hanno <strong>un solo bit</strong> come output. Queste funzioni definiscono <strong>problemi di decisione</strong> o <strong>linguaggi</strong>. Diciamo che una macchina <em>decide</em> un linguaggio <span class="math inline">\(L \subseteq \{0, 1\}^*\)</span> se calcola la funzione <span class="math inline">\(f_L : \{0, 1\}^* \rightarrow \{0, 1\}\)</span>, dove <span class="math inline">\(f_{L}(x) = 1 \iff x \in L\)</span>.</p>
<h2 id="dtime-e-dspace">DTIME e DSPACE</h2>
<p>Sia data una macchina di Turing <span class="math inline">\(M\)</span>:</p>
<ul>
<li><span class="math inline">\(time_M(x)\)</span> è il <strong>tempo di esecuzione</strong> di <span class="math inline">\(M\)</span> su input <span class="math inline">\(x\)</span>, ovvero il numero di passi richiesti per la computazione,</li>
<li><span class="math inline">\(space_M(x)\)</span> è il <strong>numero massimo</strong> di celle visitate da una qualche testina durante la computazione (considerando solo i nastri di <em>lavoro</em>),</li>
<li><span class="math inline">\(t_M(n) \coloneqq max \{time_{M}(x): |x| = n\}\)</span>, ovvero il <strong>massimo tempo</strong> (numero di passi) necessario alla macchina <span class="math inline">\(M\)</span> per una computazione sull’input <span class="math inline">\(x\)</span>,</li>
<li><span class="math inline">\(s_M(n) \coloneqq max \{space_{M}(x): |x| = n\}\)</span>, ovvero il <strong>massimo numero di celle</strong> visitate dalla macchina <span class="math inline">\(M\)</span> durante una computazione sull’input <span class="math inline">\(x\)</span>.</li>
</ul>
<p>Data una funzione <span class="math inline">\(f: N \rightarrow N\)</span> introduciamo le seguenti classi di complessità:</p>
<ul>
<li><p><span class="math inline">\(DTIME(f) \coloneqq \{ L \subseteq \Sigma^* : \exists M, L = L_M \land t_M \in O(f) \}\)</span>, ovvero:</p>
<p>Un linguaggio <span class="math inline">\(L\)</span> è in <span class="math inline">\(DTIME(f)\)</span> se e solo se esiste una macchina di Turing che in tempo <span class="math inline">\(O(f)\)</span> decide <span class="math inline">\(L\)</span>.</p></li>
<li><p><span class="math inline">\(DSPACE(f) \coloneqq \{ L \subseteq \Sigma^* : \exists M, L = L_M \land s_M \in O(f) \}\)</span>, ovvero:</p>
<p>Un linguaggio <span class="math inline">\(L\)</span> è in <span class="math inline">\(DSPACE(f)\)</span> se e solo se esiste una macchina di Turing che in spazio <span class="math inline">\(O(f)\)</span> decide <span class="math inline">\(L\)</span>.</p></li>
</ul>
<p>La D in <span class="math inline">\(DTIME\)</span> e <span class="math inline">\(DSPACE\)</span> significa “deterministico”. Infatti le macchine di Turing definite finora sono più precisamente definibili come macchine di Turing <em>deterministiche</em> in quanto per ogni dato input <span class="math inline">\(x\)</span> esiste <strong>un solo modo</strong> in cui la macchina possa terminare la sua computazione.</p>
<h2 id="tempo-e-spazio">Tempo e Spazio</h2>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span> si ha:</p>
<p><span class="math display">\[ DTIME(f) \subseteq DSPACE(f) \subseteq \sum\limits_{c \in N} DTIME( 2^{c(log + f)} )\]</span></p>
<p>La prima inclusione vale in quanto la Macchina di Turing ha bisogno di almeno un passo per visitare una nuova cella.</p>
<p>La seconda inclusione vale in quanto il <strong>numero di configurazioni</strong> della macchina con spazio fissato è <strong>finito</strong>, e la computazione deve arrestarsi entro un numero di passi <strong>pari al più</strong> a queste configurazioni (altrimenti si avrebbe un ciclo).</p>
<p>Calcoliamo il numero di configurazioni. Sia <span class="math inline">\(M = \langle Q, \Gamma, b, \Sigma, k, \delta, q_{0}, F\rangle\)</span> e <span class="math inline">\(L_M \subseteq DSPACE(f)\)</span>. Ricordiamo che una <em>configurazione</em> è una tupla</p>
<p><span class="math display">\[( q, (\sigma_1, \tau_1), \dots , (\sigma_k, \tau_k))\]</span></p>
<p>Abbiamo allora</p>
<p><span class="math display">\[t_M \le |Q| \cdot k \cdot |\Gamma|^{s_{M}(n)} \le 2^{c(log(n) + f(n)) + c}\]</span></p>
<p>per un <span class="math inline">\(c \in N\)</span> opportuno.</p>
<h2 id="riduzione-ad-un-nastro">Riduzione ad un nastro</h2>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span> si ha:</p>
<p><span class="math display">\[DSPACE(f) \subseteq DSPACE_{1}(f) \land DTIME(f) \subseteq DTIME_{1}(f^2)\]</span></p>
<p>L’idea è di simulare <span class="math inline">\(k\)</span> nastri in uno solo <strong>arricchendo l’alfabeto</strong>. Utilizzare altre <span class="math inline">\(k\)</span> “tracce” per rappresentare la posizione della testina sul nastro corrispondente:</p>
<figure>
<img src="img/RidNastri.png" title="Riduzione dei nastri" alt="Esempio di k nastri rappresentati con uno solo" /><figcaption>Esempio di k nastri rappresentati con uno solo</figcaption>
</figure>
<p>Se <span class="math inline">\(\Sigma\)</span> è l’alfabeto originale, il nuovo alfabeto è <span class="math inline">\(\Sigma&#39; \coloneqq (\Sigma \times \{ *, B\})^k\)</span>. La crescita <em>quadratica</em> è dovuta al fatto che ogni passo simulato richiede la <strong>ricerca della posizione</strong> della testina per ogni nastro: questa ricerca è limitata dalla <strong>dimensione</strong> del nastro, che a sua volta, per un solo nastro, è limitata dal <strong>tempo</strong>.</p>
<h2 id="riduzione-da-k-nastri-a-2">Riduzione da k nastri a 2</h2>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span> si ha:</p>
<p><span class="math display">\[ DTIME(f) \subseteq DTIME_2(f \cdot log(f))\]</span></p>
<p>Vogliamo mostrare una MdT universale <span class="math inline">\(\mathcal{U}\)</span> che dati un input <span class="math inline">\(x\)</span> e la descrizione di una MdT <span class="math inline">\(M\)</span> che si arresta su <span class="math inline">\(x\)</span> in <span class="math inline">\(n\)</span> passi, restituisca in output <span class="math inline">\(M(x)\)</span> in tempo <span class="math inline">\(O(n log(n))\)</span>. <span class="math inline">\(\mathcal{U}\)</span> utilizzerà il suo nastro di input/output come farebbe <span class="math inline">\(M\)</span> e possiederà un ulteriore nastro utilizzato per immagazzinare la <em>tabella di transizione</em> e lo stato corrente di <span class="math inline">\(M\)</span>.</p>
<p>Sia <span class="math inline">\(k\)</span> il numero di nastri che <span class="math inline">\(M\)</span> usa (oltre a quelli di input/output) e <span class="math inline">\(\Gamma\)</span> il suo alfabeto. Possiamo assumere che <span class="math inline">\(\mathcal{U}\)</span> usi l’alfabeto <span class="math inline">\(\Gamma^k\)</span>.</p>
<p>Possiamo quindi codificare in ogni cella del nastro <em>principale</em> <span class="math inline">\(k\)</span> simboli di <span class="math inline">\(\Gamma\)</span>, ognuno corrispondente a un simbolo da uno dei nastri di <span class="math inline">\(\mathcal{U}\)</span>. Questo significa che possiamo pensare al nastro principale di <span class="math inline">\(\mathcal{U}\)</span> non come ad un solo nastro come a <span class="math inline">\(k\)</span> <em>nastri paralleli</em>.</p>
<p>Mentre possiamo facilmente codificare il contenuto dei <span class="math inline">\(k\)</span> nastri di <span class="math inline">\(M\)</span> nei <span class="math inline">\(k\)</span> nastri paralleli di <span class="math inline">\(\mathcal{U}\)</span>, dobbiamo comunque fare i conti con il fatto che le <span class="math inline">\(k\)</span> testine di <span class="math inline">\(M\)</span> possono muoversi <strong>indipendentemente</strong> a sinistra o a destra, mentre i <span class="math inline">\(k\)</span> nastri paralleli di <span class="math inline">\(\mathcal{U}\)</span> sono costretti a muoversi insieme.</p>
<p>L’idea principale è che invece di muovere la testina, si ricopiano i caratteri non bianchi sotto la testina, effettivamente <strong>spostando</strong> i nastri paralleli.</p>
<figure>
<img src="img/Ridk2.png" title="Riduzione da k a 2" alt="Esempio di riduzione di k nastri a 2" /><figcaption>Esempio di riduzione di k nastri a 2</figcaption>
</figure>
<h3 id="codifica-dei-nastri-di-m-sul-nastro-di-u">Codifica dei nastri di M sul nastro di U</h3>
<p>Piuttusto che far corrispondere ogni nastro parallelo di <span class="math inline">\(\mathcal{U}\)</span> esattamente ad un nastro di <span class="math inline">\(M\)</span>, aggiungiamo un simbolo bianco speciale <span class="math inline">\(\square\)</span> all’alfabeto dei nastri paralleli di <span class="math inline">\(\mathcal{U}\)</span> che viene <strong>ignorato</strong> durante la simulazione ( $101 = 1  1 =  0  $, etc.).</p>
<p>Per semplicità possiamo pensare ai nastri di <span class="math inline">\(\mathcal{U}\)</span> come <em>infiniti</em> in entrambe le direzioni. Possiamo quindi indicizzarne le locazioni con <span class="math inline">\(0, \pm 1, \pm 2, \dots\)</span>. Di solito la testina sta nella locazione <span class="math inline">\(0\)</span> dei nastri paralleli. La muoveremo solo temporaneamente quando simuliamo un movimento a sinistra <strong>shift</strong>ando il nastro verso destra. Alla fine dello shift la testina ritorna alla posizione <span class="math inline">\(0\)</span>.</p>
<h3 id="invarianti">Invarianti</h3>
<p>Dividiamo ognuno dei nastri paralleli di <span class="math inline">\(\mathcal{U}\)</span> in <strong>slot</strong> che indichiamo con <span class="math inline">\(R_0,L_0,R_1,L_1, \dots\)</span>. Indichiamo la cella corrente con <span class="math inline">\(C\)</span>, inoltre la cella con locazione <span class="math inline">\(0\)</span> non sta in nessuno <em>slot</em>.</p>
<p>In generale, per ogni <span class="math inline">\(i \ge 1\)</span>, lo Slot <span class="math inline">\(R_i\)</span> contiene le <span class="math inline">\(2^{i+1}\)</span> celle collocate a destra dello Slot <span class="math inline">\(R_{i-1}\)</span>(viceversa per <span class="math inline">\(L_i\)</span>).</p>
<p>Durante l’esecuzione, vengono preservati i seguenti invarianti:</p>
<ul>
<li><p>Ognuno degli slots è <strong>completamente vuoto</strong> o <strong>completamente pieno</strong> oppure pieno <strong>esattamente a metà</strong>, ovvero il numero di simboli nello slot <span class="math inline">\(R_i\)</span> che non sono <span class="math inline">\(\square\)</span> può essere o <span class="math inline">\(0\)</span> (vuoto) o <span class="math inline">\(2^i\)</span> (metà) o <span class="math inline">\(2^{i+1}\)</span> (pieno) e lo stesso vale per <span class="math inline">\(L_i\)</span>. Assumiamo che ognuno degli slots sia inizialmente <strong>pieno a metà</strong>. Possiamo assicurarcene riempiendo, la prima volta che lo si incontra, metà di ogni con <span class="math inline">\(\square\)</span>.</p></li>
<li><p><span class="math inline">\(R_i\)</span> e <span class="math inline">\(L_i\)</span> sono l’uno <strong>pieno</strong> e l’altro <strong>vuoto</strong> ( o viceversa), oppure entrambi <strong>pieni a metà</strong>; il numero totale dei simboli significativi (diversi da <span class="math inline">\(\square\)</span>) in <span class="math inline">\(R_i \cup L_i\)</span> è dunque <span class="math inline">\(2^{i+1}\)</span>;</p></li>
<li><p>il simbolo in <span class="math inline">\(C\)</span> (locazione <span class="math inline">\(0\)</span>) <strong>contiene sempre</strong> un simbolo <strong>diverso</strong> da <span class="math inline">\(\square\)</span>.</p></li>
</ul>
<h3 id="effettuare-lo-shift">Effettuare lo shift</h3>
<p>Il vantaggio di aver impostato gli slot è che ora effettuando gli shift, non dobbiamo più spostare <em>l’intero nastro</em>, ma possiamo limitarci ad utilizzare solo <em>alcuni slot</em>.</p>
<figure>
<img src="img/Shift.png" title="Shift" alt="Esempio di operazione di shift dei 3 nastri paralleli di U" /><figcaption>Esempio di operazione di shift dei 3 nastri paralleli di U</figcaption>
</figure>
<p>L’operazione di <em>shift</em> verso sinistra opera nel modo seguente (simmetricamente verso destra):</p>
<ol type="1">
<li><p><span class="math inline">\(\mathcal{U}\)</span> trova il più piccolo <span class="math inline">\(i_0\)</span> tale per cui <span class="math inline">\(R_{i_{0}}\)</span> non sia vuoto. Notiamo che per il secondo invariante tutti gli <span class="math inline">\(L_i\)</span> per <span class="math inline">\(i &lt; i_0\)</span> saranno <strong>pieni</strong>, mentre <span class="math inline">\(L_{i_{0}}\)</span> sarà esattamente <strong>pieno a metà</strong>. Definiamo <span class="math inline">\(i_0\)</span> l’ <strong>indice</strong> di questo particolare shift.</p></li>
<li><p><span class="math inline">\(\mathcal{U}\)</span> mette il simbolo più significativo diverso da <span class="math inline">\(\square\)</span> di <span class="math inline">\(R_{i_{0}}\)</span> in <span class="math inline">\(C\)</span> (locazione <span class="math inline">\(0\)</span>) e shifta i rimanenti <span class="math inline">\(2^{i_0}\)</span> simboli da <span class="math inline">\(R_{i_{0}}\)</span> negli slot <span class="math inline">\(R_0, \dots , R_{i_{0} - 1}\)</span> riempiendo <strong>esattamente metà</strong> dei simboli di ogni slot.</p></li>
<li><p><span class="math inline">\(\mathcal{U}\)</span> effettua <strong>l’operazione simmetrica</strong> a sinistra di <span class="math inline">\(C\)</span>. svuotando a metà ciascuno degli slot pieni <span class="math inline">\(L_0, L_1, \dots, L_{i_{0} - 1}\)</span>, e mettendo tali caratteri in <span class="math inline">\(L_i\)</span> (che per <strong>l’invariante</strong> <span class="math inline">\(2\)</span> è sicuramente almeno <strong>vuoto a metà</strong>).</p></li>
<li><p>Infine <span class="math inline">\(\mathcal{U}\)</span> sposta il vecchio simbolo in lettura, opportunamente modificato, e lo mette nello slot <span class="math inline">\(L_0\)</span>.</p></li>
</ol>
<p>Alla fine dello shift, tutti gli slot <span class="math inline">\(R_0, L_0, \dots, R_{i_{0} - 1}, L_{i_{0} - 1}\)</span> sono mezze piene, <span class="math inline">\(R_0\)</span> ha <span class="math inline">\(2^{i_{0}}\)</span> simboli non <span class="math inline">\(\square\)</span> <strong>in meno</strong>, e <span class="math inline">\(L_i\)</span> ha <span class="math inline">\(2^i\)</span> simboli non <span class="math inline">\(\square\)</span> <strong>in più</strong>. Dunque <strong>gli invarianti vengono mantenuti</strong>.</p>
<h3 id="complessità-riduzione-nastri">Complessità riduzione nastri</h3>
<p>Il <strong>costo</strong> totale di una singola operazione di shift è proporzionale alla dimensione degli slot <span class="math inline">\(R_0, L_0, \dots, R_{i_{0} - 1}, L_{i_{0} - 1}\)</span> coinvolti e dunque di <span class="math inline">\(O(2^{i_{0}})\)</span>.</p>
<p>Dopo aver eseguito un operazione di shift relativa ad uno slot in posizione <span class="math inline">\(i\)</span>, tutti gli slot con <strong>indice inferiore a i</strong> (<span class="math inline">\(L_0, R_0, \dots, L_{i - 1}, R_{i - 1}\)</span>) sono <strong>mezzo pieni</strong>.</p>
<p>Questo significa che una volta effettuato uno shift con <em>indice</em> <span class="math inline">\(i\)</span>, i successivi <span class="math inline">\(2^i - 1\)</span> shift su quel particolare nastro parallelo avranno tutti indice <strong>inferiore</strong> a <span class="math inline">\(i\)</span>. Questo significa che per ognuno dei nastri paralleli, al più <span class="math inline">\(\frac{1}{2^{i}}\)</span> del numero totale degli shift avrà indice <span class="math inline">\(i\)</span>.</p>
<p>Se <span class="math inline">\(n\)</span> è il numero di passi (shift) richiesto dalla computazione e il massimo indice per gli slots è <span class="math inline">\(log (n)\)</span>, allora il tempo complessivo speso shiftando i <span class="math inline">\(k\)</span> nastri paralleli di <span class="math inline">\(\mathcal{U}\)</span> è:</p>
<p><span class="math display">\[O(\sum\limits_{i=1}^{log(n)} \frac{n}{2^{i - 1}} 2^i ) = O(n log(n))\]</span></p>
<h2 id="sequenza-di-attraversamento">Sequenza di attraversamento</h2>
<p>Sia <span class="math inline">\(M = \langle Q, \Gamma, b, \Sigma, k, \delta, q_{0}, F\rangle\)</span> ad <em>un nastro</em> e sia <span class="math inline">\(x\)</span> un input di lunghezza <span class="math inline">\(|x| = n\)</span>. Numeriamo un modo progressivo <span class="math inline">\(0, 1, \dots, n - 1\)</span> le celle che contengono l’input. La sequenza di attraversamento <span class="math inline">\(CS(x, i)\)</span> di <span class="math inline">\(x\)</span> a <span class="math inline">\(i\)</span> è la <strong>sequenza di stati necessari</strong> (<em>eventualmente infinita</em>) <span class="math inline">\(q_1, q_2, \dots \in Q\)</span>, durante la computazione di <span class="math inline">\(M\)</span> su input <span class="math inline">\(x\)</span>, al <strong>passaggio della testina</strong> alla cella <span class="math inline">\(i - 1\)</span> alla cella <span class="math inline">\(i\)</span> o viceversa.</p>
<figure>
<img src="img/SequenzaAttr.png" title="Sequenza" alt="Esempio di sequenza di attraversamento" /><figcaption>Esempio di sequenza di attraversamento</figcaption>
</figure>
<h2 id="lemma-di-attraversamento">Lemma di attraversamento</h2>
<p>Sia <span class="math inline">\(M\)</span> una macchina di Turing a <em>un nastro</em> e siano <span class="math inline">\(u, v , x, y \in \Sigma^*\)</span> tali che <span class="math inline">\(uv \in L_M \iff xy \in L_M\)</span> . Supposto</p>
<p><span class="math display">\[ CS(uv, |u|) = CS(xy, |x|)\]</span></p>
<p>allora <span class="math inline">\(uv \in L_M \iff uy \in L_M\)</span>.</p>
<figure>
<img src="img/CrossLemma.png" title="Crossing Lemma" alt="Esempio del Crossing Lemma" /><figcaption>Esempio del Crossing Lemma</figcaption>
</figure>
<p><strong>Dimostrazione</strong>. Per simmetria basta dimostrare che <span class="math inline">\(uv \in L_M \rightarrow uy \in L_M\)</span>. Consideriamo la computazione di <span class="math inline">\(uv\)</span> e <span class="math inline">\(xy\)</span> e <strong>dividiamo entrambe</strong> in corrisponenza della rispettiva <strong>posizione di crossing</strong> (i.e. <span class="math inline">\(|u|\)</span> e <span class="math inline">\(|x|\)</span>). A questo punto <strong>accoppiamo</strong> la computazione <em>di sinistra</em> di <span class="math inline">\(uv\)</span> con quella <em>di destra</em> di <span class="math inline">\(xy\)</span>. Questo porta ad una computazione che accetta <span class="math inline">\(uy\)</span>.</p>
<h2 id="un-limite-inferiore-per-la-riduzione-dei-nastri">Un limite inferiore per la riduzione dei nastri</h2>
<p>Sia <span class="math inline">\(L \coloneqq \{ w x^{|w|} w | w \in \{ 0, 1 \} ^{*} \}\)</span>. Allora:</p>
<ol type="1">
<li><span class="math inline">\(L \in DTIME_{2}(n) \subseteq DTIME_{1}(n^2)\)</span>, semplice verifica;</li>
<li><p><span class="math inline">\(L \not \in DTIME_{1}(t)\)</span> per nessun <span class="math inline">\(t \in o(n^2)\)</span>, sia <span class="math inline">\(M\)</span> una MdT ad <em>un nastro</em> per cui <span class="math inline">\(L_M = L\)</span>; notiamo le cose seguenti:</p>
<ul>
<li><p><span class="math inline">\(time_M(w x^{ |m| } w) \ge m \cdot l(w)\)</span> dove <span class="math inline">\(l(w) \coloneqq min_{ m \le i \lt 2m} \{ CS(w x^{ |m| } w, i) \}\)</span>, in quanto <strong>ogni</strong> attraversamento richiede <strong>almeno un</strong> passo;</p></li>
<li><p>ogni <em>crossing sequence</em> descrive in modo univoco una stringa <span class="math inline">\(w \in L\)</span>. Supponiamo infatti che <span class="math inline">\(CS(w x^{ |w| } w, i) = CS(w&#39; x^{ |w&#39;| } w&#39; , j)\)</span> per <span class="math inline">\(|w| \le i \lt 2 |w|\)</span> e <span class="math inline">\(| w&#39; | \le i \lt 2 | w&#39; |\)</span>. Allora per il <em>lemma di attraversamento</em> la stringa <span class="math inline">\(w x^{ |w| } w&#39; \in L\)</span> (per <span class="math inline">\(m\)</span> opportuno), che implica <span class="math inline">\(w = w&#39;\)</span>.</p></li>
<li><p>è possibile descrivere una qualunque stringa <span class="math inline">\(w\)</span> come <strong>quell’unica stringa</strong> di lunghezza <strong>minore o uguale</strong> a <span class="math inline">\(m\)</span> riconosciuta <span class="math inline">\(M\)</span> con una <strong>crossing sequence data</strong>.</p></li>
</ul></li>
</ol>
<h2 id="macchine-ad-accesso-casuale---random-access-machine">Macchine ad accesso casuale - Random Access Machine</h2>
<p>Una macchina ad <strong>accesso casuale</strong> (RAM) dispone di un insieme <strong>numerabile</strong> di locazioni di memoria in grado di contenere interi di <strong>dimensione arbitraria</strong>. Il comportamento della macchina è descritto da una <strong>sequenza di istruzioni</strong> (programma):</p>
<figure>
<img src="img/RAM.png" title="RAM" alt="Esempio di set di istruzioni di una Random Access Machine" /><figcaption>Esempio di set di istruzioni di una Random Access Machine</figcaption>
</figure>
<ul>
<li><span class="math inline">\(r_i\)</span> è il contenuto della locazione <span class="math inline">\(i\)</span> (la locazione <span class="math inline">\(0\)</span> è utilizzata come <strong>accumulatore</strong>)</li>
<li><span class="math inline">\(i_j\)</span> è l’ <span class="math inline">\(i\)</span>-esimo input</li>
<li><span class="math inline">\(k\)</span> è il <strong>Program Counter</strong> (inizializzato alla prima istruzione)</li>
</ul>
<p>Ogni istruzione ha costo <strong>unitario</strong>, indipendentemente dal fatto che opera su interi di dimensione arbitraria!</p>
<p><strong>Warning</strong>: Se l’input è <span class="math inline">\(l = (i_1, \dots, i_k)\)</span> la dimensione non è <span class="math inline">\(k\)</span>, ma</p>
<p><span class="math display">\[l(I) = \sum\limits_{j=1}^n |bin(i_j)|\]</span></p>
<h2 id="simulazione-di-una-ram-mediante-mdt-a-7-nastri">Simulazione di una RAM mediante MdT a 7 nastri</h2>
<ul>
<li>il <strong>primo</strong> nastro contiene l’ <strong>input</strong></li>
<li>il <strong>secondo</strong> nastro descrive il <strong>contenuto dei registri</strong> sotto forma di una <strong>lista di coppie</strong> <span class="math inline">\(i: r_i\)</span> separate da caratteri bianchi e concluse con <span class="math inline">\(\vartriangleleft\)</span>. Quando un registro è aggiornato, viene <em>cancellato</em> e <em>riappeso</em> in coda.</li>
<li>il <strong>terzo</strong> nastro contiene il <strong>Program Counter</strong></li>
<li>i <strong>tre nastri</strong> rimanenti sono utilizzati per le istruzioni aritmetiche (due per gli <strong>operandi</strong> e il terzo per il <strong>risultato</strong>)</li>
</ul>
<p>Gli stati della MdT sono suddivisi in <span class="math inline">\(m\)</span> gruppi, <strong>uno per ogni singola istruzione</strong> del programma da simulare.</p>
<h2 id="lemma-crescita-del-contenuto-dei-registri">Lemma crescita del contenuto dei registri</h2>
<blockquote>
<p>Al passo <span class="math inline">\(t\)</span> di una computazione su input <span class="math inline">\(I\)</span>, il contenuto di ogni registro ha una dimensione <strong>minore o uguale</strong> a <span class="math inline">\(t + l(I) + c\)</span>, dove <span class="math inline">\(c\)</span> è la dimensione della <strong>massima costante</strong> che appare nel programma.</p>
</blockquote>
<p>La dimostrazione si effettua per induzione su <span class="math inline">\(t\)</span>. Al passo <span class="math inline">\(0\)</span> il lemma è <strong>evidente</strong>. Al passo <strong>induttivo</strong> si procede per casi sull’ultima istruzione eseguita. Le istruzioni che possono <strong>aumentare sensibilmente</strong> il contenuto dei registri sono quelle <strong>aritmetiche</strong>, ma anche <em>somma e sottrazione</em> <strong>al più</strong> richiedono <strong>un solo carattere extra</strong> per il riporto finale, incrementando la dimensione dei risultati di una sola unità.</p>
<p>Si noti che il lemma <strong>non varrebbe</strong> se ad esempio tra le istruzioni aritmetiche si comprendesse anche la <strong>moltiplicazione</strong>.</p>
<h2 id="costo-della-simulazione">Costo della simulazione</h2>
<blockquote>
<p>Ogni programma RAM <span class="math inline">\(P\)</span> con complessità in tempo <span class="math inline">\(t_P(n)\)</span> <strong>può essere simulato</strong> da una MdT in tempo <span class="math inline">\(O(t_P(n)^3)\)</span>.</p>
</blockquote>
<p>Il costo di esecuzione di ogni singola istruzione è dovuto principalmente al costo di <strong>reperimento</strong> degli operandi sul nastro <span class="math inline">\(2\)</span> di simulazone della memoria.</p>
<p>Per ogni operando sono necessarie <strong>al più due</strong> scansioni del nastro (nel caso di riferimenti indiretti).</p>
<p>Il nastro ha dimensione <span class="math inline">\(O(t_P (n)^2 )\)</span>, in quanto contiene <strong>al più</strong> <span class="math inline">\(O(t_P (n))\)</span> coppie, ciascuna di dimensione <span class="math inline">\(O(t_P (n))\)</span>.</p>
<h2 id="conclusioni">Conclusioni</h2>
<p>La complessità computazionale <strong>dipende</strong> dal modello di calcolo e dalla definizione delle funzioni di costo.</p>
<p>Definizioni “ragionevoli” delle funzioni di costo permettono comunque la mutua simulazione di modelli differenti in tempi polinomiali.</p>
<h1 id="gerarchie-in-tempo-e-spazio">Gerarchie in tempo e spazio</h1>
<h2 id="macchine-di-turing-normalizzate">Macchine di Turing normalizzate</h2>
<p>Diremo che una macchina di Turing è <strong>normalizzata</strong> se è della forma</p>
<p><span class="math display">\[\langle Q = \{ 0,1, \dots , n \}, \Gamma = \{ 0, 1, 2 \}, b = 2, \Sigma = \{ 0, 1 \}, k, \delta, q_{0} = 0, F = \{ n \} \rangle\]</span></p>
<blockquote>
<p>Per ogni MdT ad <strong>un nastro</strong> sull’alfabeto <span class="math inline">\(\Sigma = \{ 0, 1 \}\)</span> ne esiste una <em>normalizzata</em> <span class="math inline">\(M&#39;\)</span> tale che <span class="math inline">\(L_M = L_{M&#39;}, t_{M&#39;} \in O(t_{M})\)</span> e <span class="math inline">\(s_{M&#39;} \in O( s_{M})\)</span>.</p>
</blockquote>
<p>Sia <span class="math inline">\(M = \langle Q_M, \Gamma_M, b_M, \Sigma, 1, \delta_m,q_{M_0}, F_M \rangle\)</span>. Ogni simbolo in <span class="math inline">\(\Gamma_M\)</span> può essere codificato da una sequenza di lunghezza <span class="math inline">\(l\)</span> opportuna di simboli in <span class="math inline">\(\Gamma_{M?} = \{ 0, 1, 2 \}\)</span> (riservando <span class="math inline">\(2^l\)</span> come codifica di <span class="math inline">\(b\)</span>). <span class="math inline">\(\delta_{M&#39;}\)</span> si ottiene da <span class="math inline">\(\delta_{M}\)</span> <em>rimpiazzando</em> ogni operazione su di un simbolo mediante una piccola sequenza di operazioni sui rispettivi blocchi. Possiamo <strong>numerare</strong> gli stati in modo crescente, ed assumere senza perdita di generalità di avere <strong>un solo stato finale</strong>. Il tempo e lo spazio <em>addizionali</em> richiesti dalla macchina normalizzata <strong>sono approssimativamente</strong> <span class="math inline">\(l\)</span> volte quelli della macchina orginaria.</p>
<h2 id="macchina-di-turing-universale">Macchina di Turing universale</h2>
<p>Esiste un encoding <strong>totale e suriettivo</strong> <span class="math inline">\(M_x\)</span> delle MdT normalizzate in strighe <span class="math inline">\(x \in \{ 0, 1 \}^{*}\)</span>, tale che esiste <span class="math inline">\(u \in \{ 0, 1 \}^{*}\)</span> e <span class="math inline">\(c \in N\)</span> per cui:</p>
<ol type="1">
<li><span class="math inline">\(L(M_{u}) = \{ \langle x, y \rangle | y \in L( M_x ) \}\)</span></li>
<li><span class="math inline">\(\forall x,y,time_{M_u} \langle x, y \rangle \le c \cdot (|x|^2 + |x| \cdot time_{M_x}(y))^2 + c\)</span></li>
</ol>
<p>Ogni transizione <span class="math inline">\(\delta (i, j) = (k, l, m)\)</span> può essere codificata da una stringa della forma:</p>
<p><span class="math display">\[w = 0^{i + 1} 10^{j + 1} 10^{k + 1} 10^{l + 1} 10^{m + 1}\]</span></p>
<p>dove <span class="math inline">\(m = 0\)</span> per <span class="math inline">\(L\)</span> e <span class="math inline">\(m = 1\)</span> per <span class="math inline">\(R\)</span>. Siccome <span class="math inline">\(Q\)</span> è finito, la funzione di transizione è codificata da un’unica stringa <span class="math inline">\(x = 1 w_0 11 w_1 11 \dots 11 w_h\)</span> che identifica in modo univoco una MdT <span class="math inline">\(M_x\)</span>. Alle stringhe <span class="math inline">\(x \in \{ 0,1 \} ^ {*}\)</span> che non sono della forma predecente associamo arbitrariamente una MdT <span class="math inline">\(M_x\)</span> che riconosce il linguaggio vuoto.</p>
<p>La MdT universale opera nel modo seguente:</p>
<ol type="1">
<li><p>Utilizziamo per semplicità una macchina di Turing <span class="math inline">\(M\)</span> a <span class="math inline">\(5\)</span> nastri. Dato l’input <span class="math inline">\(\langle x, y \rangle\)</span> la macchina <strong>ricopia</strong> innanzitutto <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> su nastri di lavoro (nastro del <strong>programma</strong> e nastro della <strong>computazione</strong>).</p>
<p><strong>Costo:</strong> <span class="math inline">\(O(|x|) + O(|y|)\)</span></p></li>
<li><p>Quindi si verifica che <span class="math inline">\(x\)</span> sia un codice <strong>valido</strong> rispetto alla <strong>codifica</strong> precedente (<strong>parsing</strong>).</p>
<p><strong>Costo:</strong> <span class="math inline">\(O( |x|^2 )\)</span></p></li>
<li><p>In caso negativo, l’input viene rifiutato; altrimenti <span class="math inline">\(M\)</span> comincia a simulare <span class="math inline">\(M_x\)</span> su input <span class="math inline">\(y\)</span> , utilizzando un <strong>ulteriore nastro</strong> per <strong>memorizzare</strong> lo stato interno di <span class="math inline">\(M_x\)</span> (nastro dello <strong>stato</strong>).</p>
<p><strong>Costo:</strong> La simulazione di ogni passo di <span class="math inline">\(M_x\)</span> richiede un tempo <span class="math inline">\(O(|x|)\)</span>, e dunque l’intera computazione costa <span class="math inline">\(O(|x| \cdots time_{M_x}(y))\)</span></p></li>
<li><p>La simulazione richiede ad ogni passo la <strong>scansione</strong> della funzione di transizione per ricercare la <strong>mossa</strong> corretta da effettuare sul nastro della <strong>computazione</strong>. Infine il risultato della computazione viene ricopiato sul nastro di <strong>output</strong>.</p>
<p><strong>Costo:</strong> <span class="math inline">\(O( time_{M_x}(y) )\)</span></p></li>
</ol>
<p>Per il teorema della riduzione dei nastri, la precedente MdT può essere simulata da una MdT ad un nastro con la complessità richiesta.</p>
<h2 id="funzioni-costruibili">Funzioni costruibili</h2>
<p>Una funzione <span class="math inline">\(f: N \rightarrow N\)</span> è detta <strong>costruibile in tempo</strong> se esiste una MdT <span class="math inline">\(M\)</span> sull’alfabeto <span class="math inline">\(\Sigma = \{ 0 \}\)</span> che calcola una funzione <span class="math inline">\(f_M\)</span> per cui:</p>
<ul>
<li>per ogni <span class="math inline">\(n, f_M( 0^n ) = 0^{f(n)}\)</span>,</li>
<li><span class="math inline">\(t_M \in O(f)\)</span></li>
</ul>
<p>Analogamente, <span class="math inline">\(f\)</span> è costruibile in spazio se valgono le stesse condizioni con <span class="math inline">\(s_M\)</span> al posto di <span class="math inline">\(t_M\)</span>.</p>
<blockquote>
<p>Ogni funzione costruibile in tempo è costruibile in spazio.</p>
</blockquote>
<p><strong>Esempio</strong> Le seguenti funzioni sono costruibili in tempo:</p>
<p><span class="math display">\[n, n \cdot log(n), n^c, c^n, n \cdot \sqrt{n}\]</span></p>
<p>La funzione <span class="math inline">\(f(n) = log(n)^c\)</span> è costruibile in spazio ma non in <strong>tempo</strong>.</p>
<h2 id="il-teorema-della-gerarchia-spazio">Il Teorema della Gerarchia (spazio)</h2>
<p>I teoremi della gerarchia riflettono l’idea intuitiva che disponendo di una maggiore quantità di risorse è effettivamente possibile affrontare problemi più complessi (ad esempio, che esistono funzioni calcolabili in tempo quadratico, ma non in tempo linerare).</p>
<p>Questi risultati forniscono <strong>una delle poche</strong> tecniche di separabilità tra classi di complessità attualmente conosciute.</p>
<blockquote>
<p>Sia <span class="math inline">\(s\)</span> una funzione costruibile in spazio e <span class="math inline">\(log \in O(s)\)</span>. Allora: <span class="math inline">\(O(s) \subseteq O(s&#39;) \iff DSPACE(s) \subseteq DSPACE(s&#39;)\)</span>.</p>
</blockquote>
<p><span class="math inline">\(\implies\)</span> vale banalmente poichè aumentando le risorse disponibili sicuramente non diminuiscono le funzioni calcolabili.</p>
<p><span class="math inline">\(\impliedby\)</span> dobbiamo dimostrare che <span class="math inline">\(O(s) \subseteq O(s&#39;) \impliedby DSPACE(s) \subseteq DSPACE(s&#39;)\)</span>.</p>
<p>Per semplicità si passa alla negazione:</p>
<p><span class="math display">\[O(s) \not \subseteq O(s&#39;) \implies DSPACE(s) \not \subseteq DSPACE(s&#39;)\]</span></p>
<p>ovvero esiste almeno un linguaggio <span class="math inline">\(L \in DSPACE(s)\)</span> tale che <span class="math inline">\(L \not \in DSPACE(s&#39;)\)</span> e quindi <span class="math inline">\(s&#39; \in o(s)\)</span>.</p>
<p>Definiamo <span class="math inline">\(L\)</span> per <em>diagonalizzazione</em>, nel modo seguente:</p>
<p><span class="math display">\[L \coloneqq \{ 0^k1x | 0^k1x \not \in L_{M_{bin(k)}} \land space_{M_{bin(k)}}( 0^k1x ) \le s(|0^k1x|) \} \]</span></p>
<p>ovvero il linguaggio delle stringhe <strong>rifiutate da</strong> <span class="math inline">\(M_{bin(k)}\)</span> usando <span class="math inline">\(\le s(|0^k1x|)\)</span> spazio.</p>
<p>Supponiamo che <span class="math inline">\(L \in DSPACE(s&#39;)\)</span>. Allora <strong>decidere</strong> <span class="math inline">\(L\)</span> si riduce alla <strong>simulazione</strong> di una macchina normalizzata <span class="math inline">\(M\)</span> (a due nastri) che usa <span class="math inline">\(\le s(|0^k1x|)\)</span> spazio (quindi in spazio <span class="math inline">\(O(s)\)</span>). In particolare, esiste un qualche intero <span class="math inline">\(k\)</span> tale che <span class="math inline">\(M_{bin(k)} = M\)</span>.</p>
<p>Siccome <span class="math inline">\(s \not \in O(s&#39;)\)</span> esistono <strong>infiniti</strong> <span class="math inline">\(n\)</span> tali per cui <span class="math inline">\(s_{M_{bin(k)}}(n) \le s(n)\)</span>, ovvero lo spazio <strong>massimo</strong> utilizzato da <span class="math inline">\(M_{bin(k)}\)</span> per decidere <span class="math inline">\(n\)</span> è minore o uguale a quello usato da <span class="math inline">\(s(n)\)</span>, e dunque ne esiste uno <strong>maggiore</strong> di <span class="math inline">\(k\)</span>.</p>
<p>Presa una qualunque stringa <span class="math inline">\(x\)</span> di lunghezza <span class="math inline">\(|x| = n - k - 1\)</span> otteniamo la seguente contraddizione:</p>
<p><span class="math display">\[0^k1x \in L \iff 0^k1x \not \in L_{M_{bin(k)}} \land space_{M_{bin(k)}}( 0^k1x ) \le s(|0^k1x|) \iff 0^k1x \not \in L_{M_{bin(k)}}\]</span></p>
<p>poichè <span class="math inline">\(space_{M_{bin(k)}}(0^k1x) \le s_{M_{bin(k)}}(0^k1x)\)</span>, per definizione e <span class="math inline">\(s_{M_{bin(k)}}(n) \le s(n) = s(|0^k1x|)\)</span>. Quindi <span class="math inline">\(L \not \in DSPACE(s&#39;)\)</span>.</p>
<p>Dobbiamo ancora dimostrar che <span class="math inline">\(L \in DSPACE(s)\)</span>. Consideriamo una macchina multi-tape <span class="math inline">\(M\)</span> che opera nel modo seguente su input <span class="math inline">\(y\)</span>:</p>
<ol type="1">
<li><p>se <span class="math inline">\(y\)</span> è della forma <span class="math inline">\(0^k1x\)</span> allora calcola <span class="math inline">\(0^{s(n)}\)</span> per <span class="math inline">\(n = | 0^k1x |\)</span>, e fallisce altrimenti</p></li>
<li><p>calcola <span class="math inline">\(bin(t)\)</span> per <span class="math inline">\(t \coloneqq |Q| \cdot 2 \cdot 3^{s(n)} \cdot |y|\)</span> dove <span class="math inline">\(Q\)</span> è l’insieme degli stati della macchina a due nastri normalizzata <span class="math inline">\(M_{bin(k)}\)</span>.</p></li>
<li><p>simula passo passo il comportamento di <span class="math inline">\(M_{bin(k)}\)</span> su input <span class="math inline">\(y\)</span> fino a <strong>terminazione</strong> oppure finchè ha utilizzato <strong>più di</strong> <span class="math inline">\(s(n)\)</span> spazio o un tempo <strong>superiore</strong> a <span class="math inline">\(t\)</span>.</p></li>
<li><p><span class="math inline">\(M\)</span> accetta l’input <span class="math inline">\(y\)</span> se la simulazione di <span class="math inline">\(M_{bin(k)}\)</span> termina <strong>rifiutandolo</strong>, oppure se si <strong>è esaurito</strong> il tempo, ma non lo spazio.</p></li>
</ol>
<p>Osserviamo che se <span class="math inline">\(M_{bin(k)}\)</span> richiede <span class="math inline">\(t\)</span> passi su input <span class="math inline">\(y\)</span> allora è in un <strong>ciclo infinito</strong>. Siccome <span class="math inline">\(s\)</span> è costruibile in spazio, allora il punto <span class="math inline">\(1\)</span> richiede spazio <span class="math inline">\(O(s)\)</span>.</p>
<p>Il calcolo di <span class="math inline">\(t\)</span> al punto <span class="math inline">\(2\)</span> richiede spazio <span class="math inline">\(O(log|y| + s(n))\)</span>.</p>
<p>La simulazione di <span class="math inline">\(M_{bin(k)}\)</span> al punto <span class="math inline">\(3\)</span> richiede spazio aggiuntivo rispetto a <span class="math inline">\(s(n)\)</span> solo per memorizzare il codice (costante) di <span class="math inline">\(M_{bin(k)}\)</span>.</p>
<p>Poichè <span class="math inline">\(log(n) \in O(s)\)</span>, e <span class="math inline">\(|y| + k \le n\)</span> tutti i passi richiedono spazio <span class="math inline">\(O(s)\)</span>, il che dimostra che <span class="math inline">\(L \in DSPACE(s)\)</span>.</p>
<h2 id="alcune-classi-di-complessità-deterministica">Alcune Classi di Complessità deterministica</h2>
<ul>
<li><span class="math inline">\(P \coloneqq \bigcup_{c \in N} DTIME(n^c)\)</span></li>
<li><span class="math inline">\(EXP \coloneqq \bigcup_{c \in N} DTIME(2^{cn})\)</span></li>
<li><span class="math inline">\(LOGSPACE \coloneqq DSPACE(log)\)</span></li>
<li><span class="math inline">\(PSPACE \coloneqq \bigcup_{c \in N}(n^c)\)</span></li>
<li><span class="math inline">\(EXPSPACE \coloneqq \bigcup_{c \in N}(2^{cn})\)</span></li>
</ul>
<p>Come corollario dei risultati precedenti abbiamo in particolare:</p>
<ul>
<li><span class="math inline">\(LOGSPACE \subseteq P \subseteq PSPACE \subset EXPSPACE\)</span></li>
<li><span class="math inline">\(LOGSPACE \subset PSPACE\)</span></li>
<li><span class="math inline">\(P \subset EXP \subseteq EXPSPACE\)</span></li>
</ul>
<p>Per nessuna inclusione <span class="math inline">\(\subseteq\)</span> si conosce se sia stretta.</p>
<h2 id="il-gap-theorem">Il Gap Theorem</h2>
<blockquote>
<p>Per ogni funzione calcolabile <span class="math inline">\(g\)</span> tale che <span class="math inline">\(g(x) \ge x\)</span> per ogni <span class="math inline">\(x\)</span>, esiste una funzione <span class="math inline">\(t(n)\)</span> tale che non esiste <span class="math inline">\(i\)</span> per cui <span class="math inline">\(t(n) \le t_{M_i}(n) \le g(t(n))\)</span> per un numero infinito di input.</p>
</blockquote>
<p>Fissiamo una enumerazione delle MdT e definiamo <span class="math inline">\(t\)</span> nel modo seguente: <span class="math inline">\(t(0) = 1\)</span> e <span class="math inline">\(t(n) = t(n-1) + k_n\)</span>, dove <span class="math inline">\(k_n = \mu\)</span></p>
<h2 id="padding">Padding</h2>
<blockquote>
<p><span class="math inline">\(EXP \not = PSPACE\)</span>.</p>
</blockquote>
<p>Per il teorema della gerarchia in tempo:</p>
<p><span class="math display">\[ EXP \subseteq DTIME(2^{n^{1.5}}) \subset DTIME(2^{n^c})\]</span></p>
<p>Supponiamo <span class="math inline">\(EXP = PSPACE\)</span> e sia <span class="math inline">\(L \in DTIME(2^{n^c})\)</span>. Allora <span class="math inline">\(L&#39; \coloneqq \{ x\#^t | x \in L \land |x| + t = |x^2|\} \in DTIME(2^n) \subseteq EXP\)</span>.</p>
<p>Per ipotesi <span class="math inline">\(L&#39; \in PSPACE\)</span>, ovvero esiste <span class="math inline">\(k \gt 0\)</span> tale che <span class="math inline">\(L&#39; \in DSPACE(n^k)\)</span>.</p>
<p>Sia <span class="math inline">\(M\)</span> la MdT corrispondente e consideriamo un’altra MdT <span class="math inline">\(M&#39;\)</span> che su input <span class="math inline">\(x\)</span> opera nel modo seguente:</p>
<ol type="1">
<li><p><strong>copia</strong> <span class="math inline">\(x\)</span> su un nastro di lavoro;</p></li>
<li><p><strong>estende</strong> <span class="math inline">\(x\)</span> con <span class="math inline">\(|x|^2 - |x|\)</span> caratteri “<span class="math inline">\(\#\)</span>”;</p></li>
<li><p>lancia una <strong>simulazione</strong> di <span class="math inline">\(M\)</span> sull’input <span class="math inline">\(x \#^{|x|^2 - |x|}\)</span>.</p></li>
</ol>
<p>Chiaramente, <span class="math inline">\(L_{M&#39;} = L\)</span> e <span class="math inline">\(M&#39;\)</span> opera in spazio <span class="math inline">\(O(n^{2k})\)</span>. Dunque, <span class="math inline">\(L \in PSPACE\)</span> e</p>
<p><span class="math display">\[DTIME(2^{n^2}) \subseteq PSPACE = EXP\]</span></p>
<p>che porta ad una contraddizione.</p>
<figure>
<img src="img/Inclusione.png" title="Inclusione tra le classi di complessità" alt="Diagramma dell’inclusione tra classi di complessità" /><figcaption>Diagramma dell’inclusione tra classi di complessità</figcaption>
</figure>
<h1 id="complessità-non-deterministica">Complessità non deterministica</h1>
<h2 id="macchina-di-turing-non-deterministica">Macchina di Turing non deterministica</h2>
<p>Una MdT <strong>non deterministica</strong> (MdTN) è definita in modo analogo alla versione deterministica, con la sola eccezione che la funzione di transizione <span class="math inline">\(\delta\)</span> è <strong>multi-valore</strong>, ovvero è una relazione:</p>
<p><span class="math display">\[\delta \subseteq Q \times \Sigma^k \times Q \times (\Sigma \times \{ L,R\})^k\]</span></p>
<ul>
<li><p>la nozione di <strong>configurazione</strong> resta invariata;</p></li>
<li><p>la nozione di <strong>passo</strong> tra configurazioni è adattata nel modo ovvio: ogni <em>configurazione</em> ammette ora <strong>più continuazioni possibili</strong>, e le computazioni non sono più sequenze lineari ma <strong>alberi</strong>;</p></li>
<li><p>la macchina si <strong>arresta</strong> su input <span class="math inline">\(x\)</span> se esiste almeno una computazione (un <em>cammino</em> nell’albero) che <strong>conduce</strong> a terminazione;</p></li>
<li><p>la macchina <strong>riconosce</strong> l’input se esiste almeno una computazione <em>terminante</em> che si arresta in uno stato di <strong>riconoscimento</strong>.</p></li>
</ul>
<h2 id="classi-di-complessità-non-deterministica">Classi di Complessità Non Deterministica</h2>
<p>Sia data una macchina di Turing non deterministica <span class="math inline">\(M\)</span>:</p>
<ul>
<li><p><span class="math inline">\(time_M(x)\)</span> è il <strong>minimo</strong> numero di passi richiesti da una qualche computazione di <span class="math inline">\(M\)</span> relativa ad <span class="math inline">\(x\)</span></p></li>
<li><p><span class="math inline">\(space_M(x)\)</span> è il <strong>minimo</strong> spazio richiesto da una qualche computazione di <span class="math inline">\(M\)</span> relativa ad <span class="math inline">\(x\)</span></p></li>
<li><p><span class="math inline">\(t_M(n) \coloneqq max(\{ n \} \cup \{time_M(x) \colon |x| = n\})\)</span></p></li>
<li><p><span class="math inline">\(s_M(n) \coloneqq max(\{ 1 \} \cup \{space_M(x) \colon |x| = n\})\)</span></p></li>
</ul>
<p>Data una funzione <span class="math inline">\(f: N \rightarrow N\)</span> introduciamo le seguenti classi di complessità:</p>
<ul>
<li><p><span class="math inline">\(NTIME(f) \coloneqq \{ L \subseteq \Sigma^* \colon \exists M, L = L_M \land t_M \in O(f)\}\)</span></p></li>
<li><p><span class="math inline">\(NSPACE(f) \coloneqq \{ L \subseteq \Sigma^* \colon \exists M, L = L_M \land s_M \in O(f)\}\)</span></p></li>
</ul>
<p>Aggiungeremo un pedice <span class="math inline">\(k\)</span> per esplicitare che <span class="math inline">\(M\)</span> ha <span class="math inline">\(k\)</span> nastri.</p>
<ul>
<li><span class="math inline">\(NP \coloneqq \bigcup_{c \in N} NTIME(n^c)\)</span></li>
<li><span class="math inline">\(NEXP \coloneqq \bigcup_{c \in N} NTIME(2^{cn})\)</span></li>
<li><span class="math inline">\(NLOGSPACE \coloneqq NSPACE(log)\)</span></li>
<li><span class="math inline">\(NPSPACE \coloneqq \bigcup_{c \in N} NSPACE(n^c)\)</span></li>
</ul>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span>:</p>
<p><span class="math display">\[DTIME(f) \subseteq NTIME(f) \land DSPACE(f) \subseteq NSPACE(f)\]</span></p>
<p>Ovvio in quanto le macchine deterministiche sono un <strong>caso particolare</strong> di quelle non deterministiche.</p>
<p>Come corollario:</p>
<ul>
<li><span class="math inline">\(P \subseteq NP\)</span></li>
<li><span class="math inline">\(LOGSPACE \subseteq NLOGSPACE\)</span></li>
<li><span class="math inline">\(EXP \subseteq NEXP\)</span></li>
<li><span class="math inline">\(PSPACE \subseteq NPSPACE\)</span></li>
</ul>
<h2 id="riduzione-nastri-per-mdtn">Riduzione nastri per MdTN</h2>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span>:</p>
<p><span class="math display">\[NSPACE(f) \subseteq NSPACE_1(f) \land NTIME(f) \subseteq NTIME_1(f^2)\]</span></p>
<p>La dimostrazione è identica a quella per il caso deterministico: i <span class="math inline">\(k\)</span> nastri sono simulati su di uno solo utilizzando un <strong>alfabeto esteso</strong> che codifica le differenti “tracce”.</p>
<p>Nel caso di MdTN, facendo un pesante uso del nondeterminismo, è anche possibile dimostrare che:</p>
<p><span class="math display">\[NTIME(f) \subseteq NTIME_1(f)\]</span></p>
<h2 id="simulazione-del-nondeterminismo-spazio">Simulazione del nondeterminismo (spazio)</h2>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span>:</p>
<p><span class="math display">\[NTIME(f) \subseteq DSPACE(id + f)\]</span></p>
<p>Sia <span class="math inline">\(M\)</span> una MdTN che riconosce <span class="math inline">\(L\)</span> in tempo <span class="math inline">\(t_M \le cf + c\)</span>. L’idea è quella di <strong>simulare</strong> le varie computazioni una alla volta, <strong>ricordando</strong> su un nastro ausiliario le scelte effettuate.</p>
<p>A questo scopo viene utilizzato un nuovo alfabeto <span class="math inline">\(\Sigma_b = \{b_1 , \dots, b_m \}\)</span> dove il numero dei caratteri dipende dal <strong>fattore massimo di branching</strong> della funzione <span class="math inline">\(\delta\)</span> (ed è dunque finito).</p>
<p>In maggiore dettaglio, la macchina <span class="math inline">\(M&#39;\)</span> che simula deterministicamente <span class="math inline">\(M\)</span> opera nel modo seguente:</p>
<ol type="1">
<li><p><strong>ricopia</strong> l’input <span class="math inline">\(x\)</span> in un nastro di lavoro,</p></li>
<li><p><strong>scrive</strong> <span class="math inline">\(0^{cf(n) + c}\)</span> su di un altro nastro,</p></li>
<li><p><strong>generano</strong> progressivamente tutte le stringhe <span class="math inline">\(w \in \{ b_1, \dots, b_m \}^*\)</span> (<strong>opzioni</strong>) di lunghezza <span class="math inline">\(|w| \le 0^{cf(n) + c}\)</span>,</p></li>
<li><p>Per ogni opzione <span class="math inline">\(w\)</span> <strong>simula</strong> la MdTN <span class="math inline">\(M\)</span> su altri nastri di lavoro per un numero di passi pari <strong>al più a</strong> <span class="math inline">\(cf(n) + c\)</span>; al passo <span class="math inline">\(i\)</span> si usa il carattere <span class="math inline">\(w(i) = b_j\)</span> per selezionare l’alternativa <span class="math inline">\(j\)</span> tra le possibili transizioni,</p></li>
<li><p>Se <span class="math inline">\(M\)</span> <strong>termina</strong> in uno stato di <em>accettazione</em>, allora si <strong>accetta</strong> <span class="math inline">\(x\)</span>, altrimenti si <strong>seleziona</strong> la parola <span class="math inline">\(w\)</span> successiva, fino ad esaurimento.</p></li>
<li><p>Se si arriva ad <strong>esaurimento</strong> delle opzioni, a llora <span class="math inline">\(x\)</span> <strong>non è</strong> riconosciuta.</p></li>
</ol>
<p>Si noti che l’arresto delle computazioni dopo al più <span class="math inline">\(cf(n) + c\)</span> passi è giustificato dal fatto che, se <span class="math inline">\(x\)</span> è riconosciuta da <span class="math inline">\(M\)</span>, <strong>esiste almeno una computazione</strong> che la riconosce entro tale tempo.</p>
<p><strong>Complessità:</strong> Il punto <span class="math inline">\(1\)</span> richiede spazio <span class="math inline">\(O(n)\)</span>; poichè <span class="math inline">\(f\)</span> è costruibile in spazio, il secondo passo richiede spazio <span class="math inline">\(O(f)\)</span>, così come i punti successivi.</p>
<h2 id="simulazione-del-nondeterminismo-tempo">Simulazione del nondeterminismo (tempo)</h2>
<p>Per ogni <span class="math inline">\(f: N \rightarrow N\)</span>:</p>
<p><span class="math display">\[NSPACE(f) \subseteq DTIME(2^{c(log+f)})\]</span></p>
<p>Sia <span class="math inline">\(M\)</span> una MdTN che accetta <span class="math inline">\(L\)</span> in spazio <span class="math inline">\(s_M \le cf + c\)</span>.</p>
<p>Il massimo numero di configurazioni differenti <strong>attraversate</strong> durante il riconoscimento dell’input <span class="math inline">\(x\)</span> (con <strong>minimo</strong> spazio) è limitato da <span class="math inline">\(2^{c&#39;(log(n) + f(n)) + c&#39;}\)</span> per un qualche <span class="math inline">\(c&#39;\)</span> opportuno (come nel caso delle macchine deterministiche).</p>
<p>Costruiamo una macchina <span class="math inline">\(M&#39;\)</span> che simula <strong>deterministicamente</strong> <span class="math inline">\(M\)</span> eseguendo una <strong>visita in larghezza</strong> (BFS) dell’albero delle computazioni relative ad un input <span class="math inline">\(x\)</span>, mantenendo gli insiemi delle configurazioni <strong>da visitare</strong> e di quelle <strong>già visitate</strong>.</p>
<p>In particolare <span class="math inline">\(M&#39;\)</span> esegue i passi seguenti:</p>
<ol type="1">
<li><p><strong>ricopia</strong> la configurazione iniziale su di un nastro di lavoro (frontiera),</p></li>
<li><p><strong>calcola</strong> <span class="math inline">\(0^{cf(n)+c}\)</span> su di un altro nastro,</p></li>
<li><p><strong>seleziona</strong> una configurazione <span class="math inline">\(\xi\)</span> dalla frontiera; se <span class="math inline">\(\xi\)</span> è in un uno stato di <strong>riconoscimento</strong> <span class="math inline">\(m&#39;\)</span> si arresta con successo; altrimenti, <strong>verifica</strong> che <span class="math inline">\(\xi\)</span> non sia già stata presa in considerazione <strong>confrontandola</strong> con una lista di configurazioni <strong>già visitate</strong> memorizzate in un nastro opportuno (nodi interni),</p></li>
<li><p><strong>aggiunge</strong> le configurazioni <strong>raggiungibili</strong> da <span class="math inline">\(\xi\)</span> alla frontiera e sposta <span class="math inline">\(\xi\)</span> sui nodi interni (le nuove configurazioni più lunghe di <span class="math inline">\(cf(n) + c\)</span> vengono <strong>ignorate</strong>),</p></li>
<li><p>se la frontiera è <strong>vuota</strong> si termina con <strong>fallimento</strong>, altrimenti torna a <span class="math inline">\(3\)</span>.</p></li>
</ol>
<p>Il <strong>primo</strong> passo richiede tempo <span class="math inline">\(O(n) = O(2^{log(n)})\)</span>.</p>
<p>Poichè <span class="math inline">\(f\)</span> è <strong>costruibile</strong> in spazio, il <strong>secondo</strong> passo richiede un tempo <span class="math inline">\(O(2^{c&#39;&#39;(log+f)})\)</span> per qualche <span class="math inline">\(c&#39;&#39; \in N\)</span>.</p>
<p>Come già osservato, il numero massimo <span class="math inline">\(maxc\)</span> di configurazioni differenti di lunghezza <strong>minore o uguale</strong> a <span class="math inline">\(cf(n) + c\)</span> da analizzare è <span class="math inline">\(2^{c&#39;(log(n)+f(n))+c&#39;}\)</span> e l’intera simulazione richiede <strong>al più</strong> tempo <span class="math inline">\(O(maxc^2) = O(2^{c&#39;&#39;&#39; (log (n)+f (n))})\)</span> per un opportuno <span class="math inline">\(c&#39;&#39;&#39; \in N\)</span>.</p>
<h2 id="simulazione-nondeterminismo">Simulazione nondeterminismo</h2>
<p>Come corollari dei risultati precedenti abbiamo le inclusioni seguenti, per ogni funzione <span class="math inline">\(f\)</span> <strong>costruibile in spazio</strong>:</p>
<p><span class="math display">\[NTIME(f) \subseteq \bigcup_{c \in N} DTIME(2^{c(id+f)})\]</span></p>
<p><span class="math display">\[NSPACE(f) \subseteq \bigcup_{c \in N} DSPACE(2^{c(log+f)})\]</span></p>
<h2 id="raggiungibilità">Raggiungibilità</h2>
<p>Sia <span class="math inline">\((V , E)\)</span> un grafo di dimensione <span class="math inline">\(n\)</span>. È possibile determinare se due nodi <span class="math inline">\(u, v\)</span> sono connessi da un cammino di lunghezza inferiore a <span class="math inline">\(2^i\)</span> con un consumo di spazio dell’ordine di <span class="math inline">\(i \cdot log(n)\)</span>.</p>
<pre><code>let rec reachable(i,u,v) =
    if i == 0 then u = v or [u,v] ∈ E
    else ∃z.(reachable(i - 1, u, z) and reachable(i - 1, z, v))</code></pre>
<p>Se esiste un cammino tra due nodi deve avere lunghezza <strong>inferiore</strong> a <span class="math inline">\(n\)</span> e dunque si può determinare la <strong>raggiungibilità</strong> tra due nodi con complessità in <strong>spazio</strong> pari a <span class="math inline">\(log(n)^2\)</span>.</p>
<p>Si noti che la complessità in <strong>tempo</strong> dell’algoritmo precedente è dell’ordine di <span class="math inline">\((2n)^i\)</span> (ovvero <span class="math inline">\(n \cdot n^{log(n)}\)</span> per <span class="math inline">\(i = log(n)\)</span>).</p>
<h2 id="teorema-di-savitch">Teorema di Savitch</h2>
<p>Sia <span class="math inline">\(s: N \rightarrow N\)</span> una funzione <strong>costruibile in spazio</strong> e tale che <span class="math inline">\(log \in O(s)\)</span>. Allora</p>
<p><span class="math display">\[NSPACE(s) \subseteq DSPACE(s^2)\]</span></p>
<p>Sia <span class="math inline">\(L \in NSPACE(s)\)</span>. Poichè <span class="math inline">\(NSPACE(s) \subseteq NSPACE_1(s)\)</span>, possiamo assumere che esista una MdTN <span class="math inline">\(M\)</span> ad un nastro che riconosce <span class="math inline">\(L\)</span> in spazio <span class="math inline">\(s_M \le c s(n) + c\)</span> per qualche <span class="math inline">\(c \in N\)</span>.</p>
<p>Costruiamo una macchina deterministica <span class="math inline">\(M&#39;\)</span> che riconosce <span class="math inline">\(L\)</span> in spazio <span class="math inline">\(s_{M&#39;} \in O(s^2)\)</span>. Supponiamo per semplicità che <span class="math inline">\(M\)</span> abbia un unica configurazione di <strong>arresto</strong> <span class="math inline">\(\Xi_h\)</span>.</p>
<p>Come osservato in precedenza, la lunghezza delle computazioni di <span class="math inline">\(M\)</span> su input <span class="math inline">\(x \in L\)</span> con <span class="math inline">\(|x| = n\)</span> è limitata da <span class="math inline">\(maxc = 2^{cs(n)+c}\)</span> per <span class="math inline">\(c\)</span> opportuno (in quanto <span class="math inline">\(log \in O(s)\)</span>). Inoltre, ognuna di queste configurazioni ha una dimensione <strong>limitata</strong> da <span class="math inline">\(cs(n) + c\)</span>.</p>
<p>Il nostro scopo è dimostrare l’esistenza di <strong>almeno una</strong> computazione dalla configurazione <strong>iniziale</strong> <span class="math inline">\(\Xi_0\)</span> a quella di <strong>arresto</strong> <span class="math inline">\(\Xi_h\)</span> che utilizza uno spazio <span class="math inline">\(O(s^2)\)</span> e fare in modo che <span class="math inline">\(M&#39;\)</span> segua questo cammino.</p>
<p>Definiamo il seguente predicato di <strong>raggiungibilità</strong> in al più <span class="math inline">\(k\)</span> passi tra due configurazioni <span class="math inline">\(\beta\)</span> e <span class="math inline">\(\gamma\)</span>:</p>
<p><span class="math display">\[reach(\beta, \gamma, k) \iff \exists \beta_0 , \dots, \beta_j \colon j \le k \land \beta_0 = \beta \land \beta_j = \gamma \land \forall i = 0, \dots, j - 1, \beta_i \vdash_M \beta_{i+1}\]</span></p>
<p>che permette una implementazione ricorsiva dell’algoritmo di ricerca. Quindi una MdT <span class="math inline">\(M&#39;\)</span>, dato l’input <span class="math inline">\(x\)</span> con <span class="math inline">\(|x| \le n\)</span> è in grado di determinare</p>
<p><span class="math display">\[reach(\Xi_0, \Xi_f, 2^{cs(n) + c})\]</span></p>
<p>con al più <span class="math inline">\(s(n)\)</span> chiamate attive innestate: l’intero stack dei record di attivazione richiede al più spazio <span class="math inline">\(O(s^2)\)</span>.</p>
<h2 id="pspace-e-npspace">PSPACE e NPSPACE</h2>
<p>Come ovvio corollario otteniamo:</p>
<p><span class="math display">\[PSPACE = NPSPACE\]</span></p>
<p>Poichè inoltre le classi deterministiche sono chiuse rispetto alla <strong>complementazione</strong> abbiamo anche:</p>
<p><span class="math display">\[NPSPACE = coNPSPACE\]</span></p>
<h2 id="il-teorema-di-immerman-e-szelepscènyi">Il Teorema di Immerman e Szelepscènyi</h2>
<blockquote>
<p>Dato un grafo <span class="math inline">\(G\)</span> con <span class="math inline">\(n\)</span> nodi e un nodo <span class="math inline">\(x\)</span>, il numero dei nodi <em>raggiungibili</em> da <span class="math inline">\(x\)</span> in <span class="math inline">\(G\)</span> può essere calcolato in <span class="math inline">\(NSPACE(log(n))\)</span>.</p>
</blockquote>
<p>Costruiremo una macchina non deterministica che calcola la funzione data nel senso che <strong>tutte</strong> le computazioni che terminano con successo <strong>concordano</strong> sul risultato, ed <strong>almeno</strong> una computazione è <strong>garantita</strong> terminare (alcune computazioni possono però fallire).</p>
<p>Sia <span class="math inline">\(n_k\)</span> il <strong>numero di nodi raggiungibili</strong> da <span class="math inline">\(x\)</span> in al più <span class="math inline">\(k\)</span> passi. La macchina opera con <strong>quattro</strong> cicli annidati.</p>
<p>Il ciclo <strong>esterno</strong> calcola <span class="math inline">\(n_k\)</span> per ogni <span class="math inline">\(k\)</span>. Il calcolo di <span class="math inline">\(n_{k+1}\)</span> richiede di conoscere <span class="math inline">\(n_k\)</span> (il cui valore è tenuto in una variabile <span class="math inline">\(Nk\)</span>) ma <strong>non i valori precedenti</strong>. Inizialmente <span class="math inline">\(Nk = n_0 = 1\)</span>.</p>
<blockquote>
<p><span class="math inline">\(Nk \coloneqq 1\)</span>; for <span class="math inline">\(k = 0\)</span> to <span class="math inline">\(n - 1\)</span> do <span class="math inline">\(Nk \coloneqq next\_num\)</span></p>
</blockquote>
<p>Il calcolo di <span class="math inline">\(next\_num\)</span> richiede di esaminare <strong>ogni nodo</strong> <span class="math inline">\(v\)</span> del grafo.</p>
<p>Si inizializza un <em>contatore</em> <span class="math inline">\(c\)</span> a <span class="math inline">\(0\)</span> e lo si incrementa tutte le volte che <strong>si trova un cammino</strong> dal nodo iniziale <span class="math inline">\(x\)</span> a <span class="math inline">\(v\)</span>. La funzione termina restituendo <span class="math inline">\(c\)</span>:</p>
<pre><code>next_num() =
    c := 0
    for v ∈ V do
        if reach(x,v) then
            c := c + 1
    return c</code></pre>
<p>Il calcolo di <code>reach(x, v)</code> avviene in modo <strong>non deterministico</strong>. Nuovamente si opera su ogni nodo <span class="math inline">\(v&#39;\)</span> del grafo.</p>
<p>Si inizializza un nuovo <em>contatore</em> <span class="math inline">\(c&#39;\)</span> a <span class="math inline">\(0\)</span> e una variabile <em>booleana</em> <span class="math inline">\(b\)</span> a <code>false</code>.</p>
<p>Si <strong>tenta non determisticamente</strong> un cammino da <span class="math inline">\(x\)</span> a <span class="math inline">\(v&#39;\)</span>; se questo <strong>esiste</strong> e se <span class="math inline">\((v , v&#39;) \in E\)</span> , allora si <strong>incrementa</strong> <span class="math inline">\(c&#39;\)</span> e si pone <span class="math inline">\(b \coloneqq true\)</span>.</p>
<p>Alla fine del loop si <strong>verifica</strong> che <span class="math inline">\(c&#39; = Nk\)</span>; se questo <strong>non succede</strong>, abbiamo perso qualche cammino per via della <strong>scelta non deterministica</strong>; il valore di <span class="math inline">\(b\)</span> non è affidabile e dunque si <strong>abortisce</strong> la computazione. Altrimenti si <strong>restituisce</strong> <span class="math inline">\(b\)</span>.</p>
<pre><code>reach(x,v) =
    c&#39; := 0; b := false
    for v&#39; ∈ V do
        if try_a_path(x, v&#39;, k) then
            c&#39; := c&#39; + 1
            if (v, v&#39;) ∈ E then b := true
    if b = false and c&#39; &lt; Nk then
        abort
    else
        return b</code></pre>
<p>Il calcolo di <code>try_a_path(x,y,k)</code> è il ciclo più <strong>interno</strong>. Semplicemente richiede di <strong>indovinare il cammino</strong>, tentando non deterministicamente i nodi <em>intermedi</em>:</p>
<pre><code>try_a_path(x, y, k) =
    s := x; b&#39; = true
    for i:= 1 to k do
        if b&#39; then
            t := guess_a_node()
            if s = t or (s, t) ∈ E then
                s := t
            else
                b&#39; := false
    b&#39; := (b&#39;)</code></pre>
<p>L’intero algoritmo richiede di <strong>memorizzare</strong> <span class="math inline">\(k\)</span>, <span class="math inline">\(Nk\)</span>, <span class="math inline">\(c\)</span>, <span class="math inline">\(c&#39;\)</span>, <span class="math inline">\(v\)</span>, <span class="math inline">\(v&#39;\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(b&#39;\)</span>, <span class="math inline">\(s\)</span>, <span class="math inline">\(t\)</span> e <span class="math inline">\(i\)</span>. Su queste variabili operiamo con <strong>confronti</strong> e <strong>incrementi unitari</strong>; numericamente sono tutte limitate da <span class="math inline">\(n\)</span>, dunque richiedono una dimensione <span class="math inline">\(log(n)\)</span>.</p>
<blockquote>
<p>Sia <span class="math inline">\(s \colon N \rightarrow N\)</span> una funzione <em>costruibile in spazio</em> e tale che <span class="math inline">\(log \in O(s)\)</span>. Allora</p>
<p><span class="math display">\[NSPACE(s) = coNSPACE(s)\]</span></p>
</blockquote>
<p>Sia <span class="math inline">\(L \in NSPACE(s)\)</span>. Poichè <span class="math inline">\(NSPACE(s) \subseteq NSPACE_1(s)\)</span>, possiamo assumere che <strong>esista</strong> una MdTN <span class="math inline">\(M\)</span> ad un nastro che <strong>riconosce</strong> <span class="math inline">\(L\)</span> in spazio <span class="math inline">\(s_M \le cs + c\)</span> per qualche <span class="math inline">\(c \in N\)</span>.</p>
<p>Dato un input <span class="math inline">\(x\)</span> di lunghezza <span class="math inline">\(|x| = n\)</span> consideriamo l’insieme <span class="math inline">\(C_x\)</span> delle <strong>configurazioni</strong> di <span class="math inline">\(M\)</span> relative ad <span class="math inline">\(x\)</span> e di dimensione <span class="math inline">\(\le cs(n) + c\)</span>.</p>
<p>Siccome <span class="math inline">\(log \in O(s)\)</span> possiamo supporre che la dimensione di <span class="math inline">\(C_x\)</span> (e dunque del suo <strong>più lungo cammino</strong>) sia <span class="math inline">\(m \le 2^{c&#39; s(n) + c&#39;}\)</span> per una opportuna costante <span class="math inline">\(c&#39;\)</span>.</p>
<p>Dobbiamo dimostrare che <span class="math inline">\(\Sigma^* \setminus L\)</span> può essere <strong>accettato</strong> da un MdTN <span class="math inline">\(M&#39;\)</span> in spazio <span class="math inline">\(O(s)\)</span>.</p>
<p>Data la macchina <span class="math inline">\(M\)</span> per <span class="math inline">\(L\)</span>, la macchina <span class="math inline">\(M&#39;\)</span> calcola innanzitutto il numero <span class="math inline">\(n = n_m(\alpha_0)\)</span> delle <strong>configurazioni raggiungibili</strong> dalla configurazione <em>iniziale</em> <span class="math inline">\(\alpha_0\)</span> di <span class="math inline">\(M\)</span> nel <em>tempo</em> <span class="math inline">\(m\)</span>.</p>
<p>Consideriamo quindi tutte le <strong>possibili configurazioni</strong> in <span class="math inline">\(C_x\)</span> e per ognuna di queste <strong>verifichiamo</strong> (non deterministicamente) che sia effettivamente <strong>raggiungibile</strong> da <span class="math inline">\(\alpha_0\)</span> e che <strong>non sia</strong> uno stato di accettazione.</p>
<p>Se abbiamo trovato <span class="math inline">\(n\)</span> configurazioni raggiungibili, <strong>nessuna delle quali</strong> di accettazione, allora <span class="math inline">\(M&#39;\)</span> <strong>accetta</strong> e altrimenti <strong>fallisce</strong> (relativamente a quella particolare computazione). Chiaramente, anche <span class="math inline">\(M&#39;\)</span> opera in spazio <span class="math inline">\(O(s)\)</span>.</p>
<figure>
<img src="img/Incl2.png" title="Inclusione tra le classi di complessità" alt="Diagramma dell’inclusione tra classi di complessità - 2" /><figcaption>Diagramma dell’inclusione tra classi di complessità - 2</figcaption>
</figure>
<h1 id="nondeterminismo-e-verifica">Nondeterminismo e Verifica</h1>
<h2 id="il-teorema-della-proiezione">Il Teorema della Proiezione</h2>
<blockquote>
<p>Dato un linguaggio <span class="math inline">\(A \subseteq \Sigma^*\)</span>, <span class="math inline">\(A \in NP\)</span> se e solo se esiste un linguaggio <span class="math inline">\(B \in P\)</span> e un polinomio <span class="math inline">\(p\)</span> tale che per ogni <span class="math inline">\(x \in \Sigma^*\)</span>,</p>
<p><span class="math display">\[x \in A \iff \exists y \colon |y| \le p(|x|) \land \langle x, y \rangle \in B\]</span></p>
</blockquote>
<p>Sia <span class="math inline">\(A \in NP\)</span>. Per il teorema della riduzione dei nastri possiamo assumere che esista una MdTN ad un nastro che <strong>riconosce</strong> <span class="math inline">\(A\)</span> in tempo <span class="math inline">\(t_M \le p\)</span> per un qualche polinomio <span class="math inline">\(p\)</span>.</p>
<p><strong>Eliminiamo</strong> il nondeterminismo utilizzando una tecnica simile a quella adottata nella prova di <span class="math inline">\(NTIME(f) \subseteq DSPACE(id +f)\)</span>. Sia <span class="math inline">\(\delta\)</span> la <em>funzione di transizione</em> nondeterministica di <span class="math inline">\(M\)</span> e sia <span class="math inline">\(m\)</span> il <strong>branching massimo</strong>. Costruiamo la macchina deterministica <span class="math inline">\(M&#39;\)</span> che <strong>accetta</strong> <span class="math inline">\(B\)</span> in tempo <span class="math inline">\(t_M \in O(p)\)</span>. <span class="math inline">\(M&#39;\)</span> lavora con un alfabeto arricchito <span class="math inline">\(\Sigma&#39;\)</span> con simboli <span class="math inline">\(b_1, \dots, b_m\)</span> utilizzati per decidere ad ogni passo il ramo della computazione da seguire.</p>
<p>In particolare, <span class="math inline">\(M&#39;\)</span> su input <span class="math inline">\(\langle x, y \rangle\)</span> <strong>simula</strong> la macchina <span class="math inline">\(M\)</span> per al più <span class="math inline">\(|y|\)</span> passi, utilizzando ad ogni passo <span class="math inline">\(i\)</span> il carattere <span class="math inline">\(y_i\)</span> della stringa <span class="math inline">\(y\)</span> per decidere la mossa da seguire. È evidente che:</p>
<p><span class="math display">\[x \in A = L_M \iff \exists y \colon |y| \le p(|x|) \land \langle x, y \rangle \in B = L_{M&#39;}\]</span></p>
<p>Viceversa, sia dato <span class="math inline">\(B \in P\)</span>, un polinomio <span class="math inline">\(p\)</span> che soddisfa le ipotesi, e una MdT <span class="math inline">\(M\)</span> tale che <span class="math inline">\(B = L_M\)</span> e <span class="math inline">\(t_M \in O(q)\)</span> per un qualche polinomio <span class="math inline">\(q\)</span>.</p>
<p>La MdTN <span class="math inline">\(M&#39;\)</span> che <strong>riconosce</strong> <span class="math inline">\(A\)</span> opera nel modo seguente: <strong>estende</strong> in modo non deterministico l’input <span class="math inline">\(x\)</span> con le <span class="math inline">\(p(|x|)\)</span> stringhe <span class="math inline">\(y\)</span> e quindi <strong>simula</strong> il comportamento di <span class="math inline">\(M\)</span> sull’input <span class="math inline">\(\langle x, y \rangle\)</span>. Chiaramente, <span class="math inline">\(M&#39;\)</span> opera in tempo <span class="math inline">\(t_M \in O(p +q)\)</span>.</p>
<h2 id="programmazione-per-tentativi-e-verifica">Programmazione per tentativi e verifica</h2>
<ul>
<li><p>Il teorema della proiezione permette di pensare alle computazioni <strong>nondeterministiche</strong> in modo <strong>deterministico</strong>.</p></li>
<li><p>L’input <span class="math inline">\(\langle x, y \rangle\)</span> consiste di due componenti: <strong>l’istanza</strong> del problema <span class="math inline">\(x\)</span> e un <strong>testimone</strong> (traccia, certificato, prova) che permette di verificare rapidamente l’appartenenza di <span class="math inline">\(x\)</span> al linguaggio.</p></li>
</ul>
<h1 id="riducibilità-e-completezza">Riducibilità e Completezza</h1>
<h2 id="classi-di-complessità-per-funzioni">Classi di Complessità per funzioni</h2>
<p>Fino ad ora abbiamo parlato di complessità relativamente al <strong>riconoscimento di linguaggi</strong>. Per ragioni di composizionalità è bene estendere la teoria per poter trattare <strong>funzioni</strong>.</p>
<p>Data una funzione <span class="math inline">\(t \colon N \rightarrow N\)</span> introduciamo le seguenti classi di complessità:</p>
<ul>
<li><p><span class="math inline">\(FTIME(t) \coloneqq \{ f \colon \Sigma^* \rightarrow \Sigma^* | \exists M, f = f_M \land t_M \in O(t)\}\)</span></p></li>
<li><p><span class="math inline">\(FSPACE(t) \coloneqq \{ f \colon \Sigma^* \rightarrow \Sigma^* | \exists M, f = f_M \land s_M \in O(t)\}\)</span></p></li>
</ul>
<p>Utilizzeremo in particolare le seguenti classi di funzioni:</p>
<ul>
<li><p><span class="math inline">\(FP \coloneqq \bigcup_{c \in N} FTIME(n^c)\)</span></p></li>
<li><p><span class="math inline">\(FLOGSPACE \coloneqq FSPACE(log)\)</span></p></li>
</ul>
<p><span class="math display">\[\implies FLOGSPACE \subseteq FP\]</span></p>
<h2 id="chiusura-per-composizione">Chiusura per composizione</h2>
<blockquote>
<p>Le classi <span class="math inline">\(FP\)</span> e <span class="math inline">\(FLOGSPACE\)</span> sono chiuse per composizione.</p>
</blockquote>
<p>Supponiamo che <span class="math inline">\(f\)</span> sia calcolata da un MdT <span class="math inline">\(M\)</span> in tempo <span class="math inline">\(t_M \le p\)</span> per un qualche polinomio <span class="math inline">\(p\)</span>.</p>
<p>Allora, per ogni input <span class="math inline">\(x\)</span> di lunghezza <span class="math inline">\(|x| = n\)</span> anche l’output deve avere <strong>lunghezza polinomiale</strong>, ovvero <span class="math inline">\(|f(x)| \le p(n)\)</span>.</p>
<p>Supponiamo inoltre che <span class="math inline">\(g\)</span> sia calcolata da una MdT <span class="math inline">\(M&#39;\)</span> in tempo <span class="math inline">\(t_{M&#39;} \le q\)</span> per un altro polinomio <span class="math inline">\(q\)</span>.</p>
<p>Sia <span class="math inline">\(M&#39;&#39;\)</span> la MdT ottenuta <strong>componendo sequenzialmente</strong> <span class="math inline">\(M\)</span> e <span class="math inline">\(M&#39;\)</span>. Abbiamo allora:</p>
<p><span class="math display">\[time_{M&#39;&#39;}(x) \le time_M(x) + time_{M&#39;}(f(x))\]</span> e dunque</p>
<p><span class="math display">\[t_{M&#39;&#39;}(n) \le t_M(n) + t_{M&#39;}(p(n)) \in O(qp)\]</span> Dunque <span class="math inline">\(g \circ f \in FP\)</span>.</p>
<p>Supponiamo ora che <span class="math inline">\(f, g \in FLOGSPACE\)</span> siano rispettivamente calcolate dalle MdT <span class="math inline">\(M\)</span> e <span class="math inline">\(M&#39;\)</span>. Non possiamo operare come in precedenza poichè l’output di una funzione <span class="math inline">\(f \in FLOGSPACE\)</span> <strong>non ha necessariamente</strong> lunghezza <strong>logaritmica</strong> (si contano solo i nastri di lavoro!).</p>
<p>Tuttavia, poichè <span class="math inline">\(FLOGSPACE \subseteq F\)</span> l’output <span class="math inline">\(f(x)\)</span> relativo a un input <span class="math inline">\(x\)</span> di lunghezza <span class="math inline">\(n = |x|\)</span> ha <strong>al più</strong> lunghezza <strong>polinomiale</strong> <span class="math inline">\(|f(x)| \le p(n)\)</span>.</p>
<p>Si noti che la memorizzazione di questo output potrebbe richiedere uno spazio <strong>più che logaritmico</strong>.</p>
<p>La soluzione è quella di cominciare l’esecuzione di <span class="math inline">\(M&#39;\)</span> e solo allorchè questa computazione richieda un <strong>nuovo carattere di input</strong> si procede nella <strong>simulazione</strong> di <span class="math inline">\(M\)</span> finché non produce un nuovo carattere di <strong>output</strong> che viene <strong>sovrascritto</strong> al precedente.</p>
<p>Questa strategia funziona poichè i nastri di input e output sono nastri su cui la testina può <strong>solo avanzare</strong>!</p>
<p>La nuova macchina richiede il seguente spazio:</p>
<p><span class="math display">\[space_{M&#39;&#39;}(x) \le space_M(x) + space_{M&#39;}(f(x))\]</span></p>
<p>e dunque</p>
<p><span class="math display">\[s_{M&#39;&#39;}(n) \le s_M(n) + s_{M&#39;}(p(n)) \in O(log + log \circ p) \subseteq O(log)\]</span></p>
<p>Dunque <span class="math inline">\(g \circ f \in LOGSPACE\)</span>.</p>
<h2 id="riducibilità">Riducibilità</h2>
<p>Siano <span class="math inline">\(A, B \in \Sigma^*\)</span> due linguaggi.</p>
<ul>
<li><p>Diremo che <span class="math inline">\(A\)</span> è <strong>riducibile in tempo polinomiale</strong> a <span class="math inline">\(B\)</span>, e scriveremo <span class="math inline">\(A \le_{P} B\)</span>, se esiste <span class="math inline">\(f \in FP\)</span> tale che per ogni <span class="math inline">\(x \in \Sigma^*\)</span>,</p>
<p><span class="math display">\[x \in A \iff f(x) \in B\]</span></p></li>
<li><p>analogamente, diremo che <span class="math inline">\(A\)</span> è <strong>riducibile in spazio logaritmico</strong> a <span class="math inline">\(B\)</span>, e scriveremo <span class="math inline">\(A \le_{L} B\)</span> se esiste <span class="math inline">\(f \in FLOGSPACE\)</span> che realizza l’equazione precedente.</p></li>
</ul>
<blockquote>
<p>Le relazioni <span class="math inline">\(\le_{P}\)</span> e <span class="math inline">\(\le_{L}\)</span> sono <em>preordini</em>.</p>
</blockquote>
<p>La relazione deriva dalla definizione e la transitività dalla chiusura rispetto alla composizione di <span class="math inline">\(FP\)</span> e <span class="math inline">\(FLOGSPACE\)</span>.</p>
<p>Indicheremo con <span class="math inline">\(\equiv_{P}\)</span> e <span class="math inline">\(\equiv_{L}\)</span> le equivalenze indotte.</p>
<h2 id="chiusura-per-riducibilità">Chiusura per riducibilità</h2>
<p>Sia <span class="math inline">\(C\)</span> una classe di linguaggi e <span class="math inline">\(\le\)</span> un qualche <em>preordine</em>. Diremo che che <span class="math inline">\(C\)</span> è chiusa rispetto a <span class="math inline">\(\le\)</span>, se</p>
<p><span class="math display">\[A \le B \land B \in C \rightarrow A \in C\]</span></p>
<ul>
<li><p>Le classi <span class="math inline">\(P, NP, PSPACE\)</span> sono chiuse rispetto alla riducibilità in <strong>tempo polinomiale</strong> <span class="math inline">\(\le_{P}\)</span>.</p></li>
<li><p>Le classi <span class="math inline">\(LOGSPACE, NLOGSPACE, P, NP, PSPACE\)</span> sono chiuse rispetto alla riducibilità in <strong>spazio logaritmico</strong> <span class="math inline">\(\le_{L}\)</span></p></li>
</ul>
<h2 id="problemi-ardui-e-completi">Problemi ardui e completi</h2>
<p>Sia <span class="math inline">\(C\)</span> una <em>classe</em> di linguaggi e <span class="math inline">\(\le\)</span> un <em>preordine</em> tra di essi. Sia <span class="math inline">\(B\)</span> un linguaggio:</p>
<ul>
<li><p><span class="math inline">\(B\)</span> è <strong><span class="math inline">\(C\)</span>-arduo</strong> rispetto a <span class="math inline">\(\le\)</span>, se ogni <span class="math inline">\(A \in C\)</span> è <strong>riducibile</strong> a B, ovvero <span class="math inline">\(A \le B\)</span>.</p></li>
<li><p><span class="math inline">\(B\)</span> è <strong><span class="math inline">\(C\)</span>-completo</strong> rispetto a <span class="math inline">\(\le\)</span>, se <span class="math inline">\(B \in C\)</span> e <span class="math inline">\(B\)</span> è <strong><span class="math inline">\(C\)</span>-arduo</strong>.</p></li>
</ul>
<p>Nel caso in cui non sia esplicitato altrimenti, si assume che il preordine sia la <strong>riducibilità polinomiale</strong> <span class="math inline">\(\le_{P}\)</span>.</p>
<h2 id="mdtn-universale">MdTN Universale</h2>
<blockquote>
<p>Esiste un <em>encoding</em> totale e suriettivo <span class="math inline">\(M_x\)</span> delle MdTN normalizzate (ad un solo nastro) mediante stringhe <span class="math inline">\(x \in \{0,1\}^*\)</span> tale che <span class="math inline">\(\exists u \in \{0,1\}^*\)</span> con le seguenti proprietà:</p>
</blockquote>
<ul>
<li><span class="math inline">\(L_{M_u} = \{ \langle x, y\rangle \colon y \in L_{M_x} \}\)</span></li>
<li><span class="math inline">\(\forall x, y, \exists c, time_{M_u} \langle x, y \rangle \le c \cdot (time_{M_x}(y))^2 + c\)</span></li>
</ul>
<p>Il non determinismo dell’interprete permette di simulare il non determinismo descritto dalla funzione di transizione delle singole macchine.</p>
<h2 id="problema-limitato-della-fermata">Problema limitato della fermata</h2>
<blockquote>
<p><span class="math inline">\(BHP \coloneqq \{\langle x, y, 0^t \rangle |\)</span>MdTN <span class="math inline">\(M_x\)</span> accetta <span class="math inline">\(y\)</span> in tempo <span class="math inline">\(time_{M_x}(y) \le t\}\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p>
</blockquote>
<p>La macchina universale <span class="math inline">\(M_u\)</span> può <strong>simulare</strong> <span class="math inline">\(M_x\)</span> su input <span class="math inline">\(y\)</span> per <span class="math inline">\(t\)</span> passi e <strong>verificare</strong> se arriva in uno stato di <strong>accettazione</strong> in un tempo inferiore a <span class="math inline">\(p(t)\)</span> per un qualche polinomio <span class="math inline">\(p\)</span>.</p>
<p>Viceversa se <span class="math inline">\(A \in NP\)</span> allora esiste una MdTN <span class="math inline">\(M_x\)</span> che <strong>riconosce</strong> <span class="math inline">\(A\)</span> in tempo <span class="math inline">\(t_{M_x} \le p\)</span> per un qualche polinomio <span class="math inline">\(p\)</span>. La funzione <span class="math inline">\(f\)</span> di <strong>riduzione</strong> che mostra che <span class="math inline">\(A \le_{P} BHP\)</span> è semplicemente</p>
<p><span class="math display">\[f(y) \coloneqq \langle x, y, 0^{p(|y|)} \rangle\]</span></p>
<p>e <span class="math inline">\(f \in FP\)</span> poichè i polinomi sono <strong>costruibili in tempo</strong>.</p>
<h2 id="p-vs.np">P vs. NP</h2>
<blockquote>
<p>Se per qualche problema <strong><span class="math inline">\(NP\)</span>-completo</strong> <span class="math inline">\(A\)</span> si ha <span class="math inline">\(A \in P\)</span>, allora <span class="math inline">\(P = NP\)</span>.</p>
</blockquote>
<ul>
<li><p><span class="math inline">\(P \subseteq NP\)</span>, quindi dobbiamo dimostrare <strong>l’inclusione opposta</strong>.</p></li>
<li><p>Se <span class="math inline">\(B \in NP\)</span>, per la <strong><span class="math inline">\(NP\)</span>-completezza</strong> di <span class="math inline">\(A\)</span> si ha <span class="math inline">\(B \le_{P} A\)</span>.</p></li>
<li><p>Siccome <span class="math inline">\(P\)</span> è <strong>chiusa</strong> per la riducibilità in <strong>tempo polinomiale</strong> e per ipotesi <span class="math inline">\(A \in P\)</span>, anche <span class="math inline">\(B \in P\)</span>.</p></li>
</ul>
<blockquote>
<p>Se <span class="math inline">\(P = NP\)</span> allora ogni problema non banale <span class="math inline">\(A \in NP\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p>
</blockquote>
<p>Basta osservare che per ogni <strong>coppia</strong> di problemi <strong>non banali</strong> <span class="math inline">\(B, A \in P\)</span> si ha <span class="math inline">\(B \le_{P} A\)</span> (supposto <span class="math inline">\(a_0 \in A\)</span> e <span class="math inline">\(a_1 \not \in A\)</span> basta modificare l’algoritmo di decisione per <span class="math inline">\(B\)</span> in un algoritmo che restituisca <span class="math inline">\(a_0\)</span> al posto di <span class="math inline">\(1\)</span> e <span class="math inline">\(a_1\)</span> al posto di <span class="math inline">\(0\)</span>).</p>
<h1 id="il-problema-della-soddisfacibilità">Il Problema della Soddisfacibilità</h1>
<p>Sia <span class="math inline">\(\Sigma \coloneqq \{0, 1, \lnot, \land, \lor, \implies, (, ), [, ]\}\)</span>.</p>
<p><span class="math inline">\(SAT \subseteq \Sigma^*\)</span> è l’insieme delle <strong>formule booleane <em>soddisfacibili</em></strong>, cioè l’insieme delle formule che sono <strong>vere</strong> rispetto ad un qualche <strong>assegnamento</strong> di valori di verità ai simboli proposizionali.</p>
<p>Il simbolo proposizionale <span class="math inline">\(P_k\)</span> è codificato da una stringa della forma <span class="math inline">\([bin(k)]\)</span> , mentre gli altri simboli di <span class="math inline">\(\Sigma\)</span> hanno la loro interpretazione logica usuale.</p>
<p>Ad esempio, <span class="math inline">\([0] \rightarrow [1] \in SAT\)</span> ma <span class="math inline">\([0] \land \lnot [0] \not \in SAT\)</span>.</p>
<p><span class="math inline">\(3SAT \subseteq SAT\)</span> è l’insieme delle formule <strong>soddisfacibili</strong> in <em>forma normale congiuntiva</em> (ovvero le formule composte dalla <strong>congiunzione</strong> di clausole contenenti solo <span class="math inline">\(\lor\)</span> e <span class="math inline">\(\lnot\)</span>, i.e <span class="math inline">\((P \lor Q \lor R)\land(S \lor \lnot T \lor V)\)</span>) e tali per cui ogni clausola contiene <strong>esattamente tre</strong> variabili distinte.</p>
<h2 id="teorema-di-cook">Teorema di Cook</h2>
<blockquote>
<p><span class="math inline">\(SAT\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong></p>
</blockquote>
<p>È facile vedere che <span class="math inline">\(SAT \in NP\)</span> perchè un assegnamento <strong>soddisfacibile</strong> può servire da <strong>certificato</strong> che una formula sia <strong>soddisfacibile</strong>. Dobbiamo dimostrare la <strong>completezza</strong>.</p>
<p>Sia <span class="math inline">\(L \in NP\)</span> e consideriamo una MdTN con un nastro <span class="math inline">\(M = (Q, q_0 , F, \Sigma, \Gamma, B, 1, \delta)\)</span> tale che <span class="math inline">\(L_M = L\)</span> (senza perdita di generalità, supporremo che <span class="math inline">\(M\)</span> operi sul seminastro destro). Supponiamo inoltre che <span class="math inline">\(t_M \le p\)</span> per un qualche polinomio <span class="math inline">\(p\)</span>.</p>
<p>Il nostro obiettivo è definire una formula <span class="math inline">\(\Psi_x\)</span> per ogni <span class="math inline">\(x\)</span> tale che <span class="math inline">\(x \in L \iff \Psi_x \in SAT\)</span>.</p>
<p>Supposto <span class="math inline">\(|x| = n\)</span>, <strong>deve esistere</strong> una computazione che porta al <strong>riconoscimento</strong> di <span class="math inline">\(x\)</span> attraversando <strong>al più</strong> <span class="math inline">\(p(n)\)</span> configurazioni. Inoltre, ogni configurazione ha una <em>dimensione</em> che <strong>non eccede</strong> <span class="math inline">\(p(n)\)</span>.</p>
<p>In particolare, codificheremo le configurazioni con stringhe sull’alfabeto <span class="math inline">\(\Gamma&#39; = \Gamma \cup (Q \times \Gamma )\)</span> dove ogni simbolo <span class="math inline">\(a\)</span> in una configurazione corrisponde o a un simbolo in <span class="math inline">\(\Gamma\)</span> o un simbolo in <span class="math inline">\(Q \times \Gamma\)</span> (in questo caso il simbolo <span class="math inline">\(a = \langle q, s \rangle\)</span> indica che la <strong>testina</strong> è sul simbolo <span class="math inline">\(s\)</span> e lo <strong>stato corrente</strong> è <span class="math inline">\(q\)</span>).</p>
<p>Abbiamo quindi una matrice spazio-tempo di <strong>dimensione</strong> <span class="math inline">\(p(n)^2\)</span> il cui contenuto può essere descritto mediante variabili proposizionali <span class="math inline">\(y_{i,j,a}\)</span>:</p>
<blockquote>
<p><span class="math inline">\(y_{i,j,a} = true \iff\)</span> il carattere <span class="math inline">\(j\)</span> della <span class="math inline">\(i\)</span>-esima configurazione contiene il carattere <span class="math inline">\(a\)</span></p>
</blockquote>
<p>Costruiremo una formula <em>booleana</em> <span class="math inline">\(\Psi_x\)</span> con le variabili <span class="math inline">\(y_{i,j,a}\)</span> tali per cui <span class="math inline">\(\Psi_x\)</span> è soddisfacibile se e solo se le seguenti condizioni valgono:</p>
<ol type="1">
<li><p>I bordi non possono essere oltrepassati:</p>
<p><span class="math inline">\(\Psi_0 \coloneqq \bigwedge \limits_{i=0}^{p(n)}(y_{i, 0, B} \land y_{i, p(n) + 1, B})\)</span></p></li>
<li><p>Per ogni coppia <span class="math inline">\((i, j)\)</span>, con <span class="math inline">\(0 \le i \le p(n)\)</span> e <span class="math inline">\(1 \le j \le p(n)\)</span>, c’è esattamente un simbolo <span class="math inline">\(a \in \Gamma&#39;\)</span> tale che <span class="math inline">\(y_{i,j,a} = 1\)</span>. Basandoci sull’interpretazione precedente delle variabili <span class="math inline">\(y_{i,j,a}\)</span> significa che ad ogni istante <strong>ogni cella</strong> dell’<span class="math inline">\(i\)</span>-esima configurazione contiene <em>esattamente</em> un simbolo.</p>
<p><span class="math inline">\(\Psi_1 \coloneqq \bigwedge \limits_{i=0}^{p(n)} \bigwedge \limits_{j=0}^{p(n)} (\bigvee \limits_{a \in \Gamma&#39;} y_{i, j, a}) \land \bigwedge \limits_{a, b, \in \Gamma&#39;, a \not = b} (\lnot y_{i, j, a} \lor \lnot y_{i, j, b})\)</span></p></li>
<li><p>Per ogni coppia <span class="math inline">\((j, a)\)</span>, con <span class="math inline">\(1 \le j \le p(n)\)</span> e <span class="math inline">\(a \in \Gamma&#39;\)</span>, <span class="math inline">\(y_{0, j, a} = 1\)</span> se e solo se il <span class="math inline">\(j\)</span>-esimo simbolo nella configurazione iniziale di <span class="math inline">\(M(x)\)</span> è <span class="math inline">\(a\)</span>. Ovvero la configurazione <span class="math inline">\(0\)</span> è quella <strong>iniziale</strong>:</p>
<p><span class="math inline">\(\Psi_2 \coloneqq y_{0, 1, \langle q_0, x_1 \rangle} \land \bigwedge \limits_{j=2}^{n} y_{0, j, x_j} \land \bigwedge \limits_{j=n+1}^{p(n)} y_{0, j, B}\)</span></p></li>
<li><p><span class="math inline">\(y_{p(n), j, a} = 1\)</span> per qualche <span class="math inline">\(j\)</span>, <span class="math inline">\(1 \le j \le p(n)\)</span>, e qualche <span class="math inline">\(a \in F \times \Gamma\)</span>. (Questo significa che la <span class="math inline">\(p(n)\)</span>-esima configurazione di <span class="math inline">\(M(x)\)</span> contiene uno <strong>stato finale</strong>)</p>
<p><span class="math inline">\(\Psi_3 \coloneqq \bigvee \limits_{j=1}^{p(n)} \bigvee \limits_{a \in F \times \Gamma} y_{p(n), j, a}\)</span></p>
<p>Infine, deve essere possibile <strong>transire</strong> da una configurazione alla successiva. Questo significa che:</p></li>
<li><p>le celle non adiacenti alla testina di lettura devono essere ricopiate</p>
<p><span class="math inline">\(\Psi_4 \coloneqq \bigwedge \limits_{i=0}^{p(n) - 1} \bigwedge \limits_{j=1}^{p(n)} \bigwedge \limits_{a, b, c \in \Gamma} (y_{i, j-1, a} \land y_{i, j, b} \land y_{i, j+1, c} \rightarrow y_{i+1, j, b})\)</span></p></li>
<li><p>le celle adiacenti alla testina devono essere <strong>modificate</strong> in accordo alla <em>funzione di transizione</em> <span class="math inline">\(\delta\)</span></p>
<p><span class="math inline">\(\Psi_5 \coloneqq \bigwedge \limits_{i=0}^{p(n) - 1} \bigwedge \limits_{j=1}^{p(n)} \bigwedge \limits_{(q, a) \in Q \times \Gamma} \Delta_{q, a, i, j}\)</span></p></li>
</ol>
<p>per un <span class="math inline">\(\Delta_{q, a, i, j}\)</span> opportuno che andiamo a precisare.</p>
<p>La formula <span class="math inline">\(\Delta_{q, a, i, j}\)</span> descrive le possibili evoluzioni della configurazione al passo <span class="math inline">\(i\)</span>, <strong>conseguenti</strong> all’esecuzione di una <em>mossa non determinsitica</em> della macchina.</p>
<p>Supponiamo ad esempio che <span class="math inline">\(\delta(q, a) = \{(q&#39;, a&#39;, R), (q&#39;&#39;, a&#39;&#39;, L)\}\)</span>. Allora:</p>
<p><span class="math display">\[\Delta_{q, a, i, j} \coloneqq ( y_{i, j-1, b} \land y_{i, j, \langle q, a \rangle} \land y_{i, j+1, c} \rightarrow (y_{i+1, j-1, b} \land y_{i+1, j, a&#39;} \land y_{i+1, j+1, \langle q&#39;, c \rangle})\lor(y_{i+1, j-1, \langle q&#39;&#39;, b \rangle} \land y_{i+1, j, a&#39;&#39;} \land y_{i+1, j+1, c}))\]</span></p>
<p>Per <strong>altri</strong> valori della funzione di transizione, <span class="math inline">\(\Delta_{q, a, i ,j}\)</span> è definita in modo analogo.</p>
<p>La <strong>congiunzione</strong> <span class="math inline">\(\Psi_x \coloneqq \Psi_0 \land \Psi_1 \land \Psi_2 \land \Psi_3 \land \Psi_4 \land \Psi_5\)</span> verifica la proprietà cercata:</p>
<p><span class="math display">\[x \in L \iff \Psi_x \in SAT\]</span></p>
<p>Resta da appurare la <strong>complessità</strong> computazionale della funzione <span class="math inline">\(f \colon x \mapsto \Psi_x\)</span>.</p>
<p>È evidente che tutte la formule <span class="math inline">\(\Psi_i\)</span> possono essere <strong>costruite</strong> in tempo <span class="math inline">\(O(p)\)</span> e dunque</p>
<p><span class="math display">\[f \in FP\]</span></p>
<p><strong>Remark:</strong> È in effetti possibile dimostrare che <span class="math inline">\(f \in LOGSPACE\)</span></p>
<h2 id="analogie-tra-calcolabilità-e-complessità">Analogie tra Calcolabilità e Complessità</h2>
<p><span class="math display">\[RE \implies NP\]</span> <span class="math display">\[Ricorsivo \implies P\]</span> <span class="math display">\[\le_m \implies \le_{P}\]</span> <span class="math display">\[K \implies SAT\]</span></p>
<h2 id="np-completezza-di-3sat"><span class="math inline">\(NP\)</span>-completezza di 3SAT</h2>
<blockquote>
<p><span class="math inline">\(3SAT\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p>
</blockquote>
<p>Ricodiamo che le formule in <span class="math inline">\(3SAT\)</span> sono <strong>congiunzioni</strong> di clausole <strong>disgiuntive</strong> composte da <strong>esattamente tre</strong> letterali.</p>
<p>È facile trasformare una clausola arbitraria in un insieme di clausole a <strong>tre-letterali</strong>, aggiungendo nuove variabili, preservando la soddisfacibilitá.</p>
<p>Ad esempio:</p>
<p><span class="math display">\[\{A, \lnot B\} \leadsto \{ A, \lnot B, C\} \land \{ A, \lnot B, \lnot C \}\]</span></p>
<p><span class="math display">\[\{A, B, C, \lnot D\} \leadsto \{A, B, E\} \land \{\lnot E, C, \lnot D\}\]</span></p>
<p>Bisogna però prestare attenzione alla trasformazione della formula di partenza in forma a clausole (Forma Normale Congiuntiva), in quanto potrebbe portare ad una <strong>esplosione esponenziale</strong>.</p>
<p>Ad esempio, la formula</p>
<ul>
<li><span class="math inline">\((*)\)</span> <span class="math inline">\((x_1 \land y_1) \lor \dots \lor (x_n \land y_n)\)</span></li>
</ul>
<p>genera le <span class="math inline">\(2^n\)</span> clausole</p>
<p><span class="math display">\[\{x_1, \dots, x_{n-1}, x_n\}, \{x_1, \dots, x_{n-1}, y_n\}, \dots, \{y_1, \dots, y_{n-1}, y_n\}\]</span></p>
<p>Tuttavia questa costruzione mira a <strong>preservare</strong> l’equivalenza logica, mentre siamo solo interessati alla <strong>soddisfaciblità</strong>.</p>
<p>In questo caso, possiamo trasformare <span class="math inline">\((*)\)</span> nel modo seguente:</p>
<p><span class="math display">\[\{z_1, \dots, z_n\},\{\lnot z_1, x_1\},\{\lnot z_1, y_1\}, \dots, \{\lnot z_n, x_n\}, \{\lnot z_n, y_n\}\]</span></p>
<p>Adottando la tecnica precedente è possibile dimostrare che <strong>ogni formula</strong> logica può essere trasformata in forma normale congiuntiva (<span class="math inline">\(3\)</span>-letterale) <em>preservando la soddisfacibilità</em> con una crescita al più <strong>polinomiale</strong>.</p>
<h2 id="il-problema-del-ricoprimento---vertex-cover">Il Problema del Ricoprimento - Vertex Cover</h2>
<p>Ricordiamo che, dato un grafo <span class="math inline">\(G = (V , E )\)</span>, un ricoprimento è un sottoinsieme <span class="math inline">\(V&#39; \subseteq V\)</span> tale che</p>
<p><span class="math display">\[\forall (u, v) \in E, u \in V&#39; \lor v \in V&#39;\]</span></p>
<blockquote>
<p>Il problema <span class="math inline">\(VC\)</span> di decidere se un grafo ha un <strong>ricoprimento</strong> <span class="math inline">\(V&#39;\)</span> di dimensione <span class="math inline">\(|V&#39;| \le k\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p>
</blockquote>
<p>Abbiamo già dimostrato che il problema del ricoprimento è di facile <strong>verifica</strong> e dunque appartiene a <span class="math inline">\(NP\)</span>. Per dimostrarne la <strong>completezza</strong> facciamo vedere che <span class="math inline">\(3SAT \le_P VC\)</span>.</p>
<h3 id="sat-vs.ricoprimento">3SAT vs. Ricoprimento</h3>
<p>Sia data una formula <span class="math inline">\(F\)</span> in <span class="math inline">\(3SAT\)</span>, siano <span class="math inline">\(C_1, C_2, \dots, C_m\)</span> le sue <strong>clausole</strong>, con <strong>variabili proposizionali</strong> in <span class="math inline">\(X_1, \dots, X_n\)</span> (possiamo supporre che <span class="math inline">\(n \le 3m\)</span>).</p>
<p>Costruiamo un grafo <span class="math inline">\(GF\)</span> con <span class="math inline">\(2n + 3m\)</span> <strong>nodi</strong> nel modo seguente.</p>
<p>Abbiamo <span class="math inline">\(2n\)</span> vertici <span class="math inline">\(x_i\)</span> e <span class="math inline">\(\overline{x}_i\)</span>, e <span class="math inline">\(3m\)</span> vertici <span class="math inline">\(c_{j,k}\)</span> per <span class="math inline">\(k = 1, 2, 3\)</span> <strong>connessi tra di loro</strong> nel modo seguente:</p>
<ul>
<li><p><span class="math inline">\(x_i\)</span> <strong>è connesso</strong> a <span class="math inline">\(\overline{x_i}\)</span> per ogni <span class="math inline">\(i = 1, \dots, n\)</span></p></li>
<li><p><span class="math inline">\(c_{j, 1}, c_{j, 2}, c_{j, 3}\)</span> <strong>sono connessi in circolo</strong> per ogni <span class="math inline">\(j = 1, \dots, m\)</span></p></li>
<li><p>per ogni <span class="math inline">\(C_j = (Y_1 \lor Y_2 \lor Y_3)\)</span>, per <span class="math inline">\(k = 1, 2, 3\)</span> il vertice <span class="math inline">\(c_{j, k}\)</span> <strong>è connesso a</strong> <span class="math inline">\(x_i\)</span> se <span class="math inline">\(Y_k = X_i\)</span>, ed <strong>è connesso a</strong> <span class="math inline">\(\overline{x_i}\)</span> se <span class="math inline">\(Y_k = \lnot X_i\)</span></p></li>
</ul>
<p>Ad esempio, la formula</p>
<p><span class="math display">\[F = (X_1 \lor \lnot X_2 \lor X_3) \land (\lnot X_1 \lor X_3 \lor \lnot X_4) \land (\lnot X_4) \land (\lnot X_2 \lor \lnot X_3 \lor X_4)\]</span></p>
<p>genera il grafo:</p>
<figure>
<img src="img/3SAT_VC.png" title="3SAT vs. VC" alt="Riduzione di 3SAT a VC" /><figcaption>Riduzione di 3SAT a VC</figcaption>
</figure>
<p>Vogliamo dimostrare che la formula <span class="math inline">\(F\)</span> è <strong>soddisfacibile</strong> se e solo se esiste un <strong>ricoprimento</strong> <span class="math inline">\(S\)</span> di <span class="math inline">\(GF\)</span> di cardinalità <span class="math inline">\(|S| \le n + 2m\)</span> (si osservi che il grafo può essere <strong>costruito in tempo polinomiale</strong>).</p>
<p>Supponiamo che <span class="math inline">\(F\)</span> sia <strong>soddisfacibile</strong> e sia <span class="math inline">\(v\)</span> un <strong>assegnamento</strong> di valori di verità alle variabili che rende vera <span class="math inline">\(F\)</span>.</p>
<p>Sia <span class="math inline">\(S_1 = \{x_i |v (X_i) = true\} \cup \{\overline{x_i} |v (X_i) = false\}\)</span>.</p>
<p>Se inoltre <span class="math inline">\(v\)</span> soddisfa <span class="math inline">\(F\)</span> deve soddisfare <strong>ognuna</strong> delle sue clausole, e dunque per ogni <span class="math inline">\(j = 1, \dots, m\)</span> esiste <span class="math inline">\(k_j \in \{1, 2, 3\}\)</span> tale che <span class="math inline">\(c_{j,k_ j}\)</span> è <strong>adiacente</strong> a qualche vertice in <span class="math inline">\(S_1\)</span>.</p>
<p>Sia <span class="math inline">\(S_2 = \{c_{j,k} |j = 1, \dots, m \land k \lnot = k_j \}\)</span>. Allora <span class="math inline">\(S \coloneqq S_1 \cup S_2\)</span> è un <strong>ricoprimento</strong> e la sua cardinalità è <span class="math inline">\(n + 2m\)</span>.</p>
<p>Viceversa, supponiamo che esista un <strong>ricoprimento</strong> <span class="math inline">\(S\)</span> di dimensione minore o uguale a <span class="math inline">\(n + 2m\)</span>. Allora ogni triangolo <span class="math inline">\(c_{j,1} , c_{j,2}, c_{j,3}\)</span> ha <strong>almeno due</strong> vertici in <span class="math inline">\(S\)</span> e ogni arco <span class="math inline">\((x_i , \overline{x_i})\)</span> ha <strong>almeno un</strong> vertice in <span class="math inline">\(S\)</span>.</p>
<p>Dunque <span class="math inline">\(S\)</span> ha esattamente <span class="math inline">\(n + 2m\)</span> elementi, con <strong>esattamente due</strong> vertici per ogni triangolo e <strong>un vertice</strong> per ogni arco <span class="math inline">\((x_i, \overline{x_i})\)</span>. Posto allora</p>
<p><span class="math display">\[v(X_i) = true \iff x_i \in S\]</span></p>
<p><span class="math inline">\(v\)</span> verifica ogni clausola <span class="math inline">\(C_j\)</span>, in quanto <strong>rende vero</strong> il letterale adiacente al vertice <span class="math inline">\(c_{j,k} \not \in S\)</span>.</p>
<p>Dunque, <span class="math inline">\(F \in 3SAT\)</span>.</p>
<h3 id="esempi-di-interpretazioniricoprimenti">Esempi di interpretazioni/ricoprimenti</h3>
<p><span class="math display">\[F = (X_1 \lor \lnot X_2 \lor X_3) \land (\lnot X_1 \lor X_3 \lor \lnot X_4) \land (\lnot X_4) \land (\lnot X_2 \lor \lnot X_3 \lor X_4)\]</span></p>
<ul>
<li><span class="math inline">\(v(X_1) = 1, v(X_2) = 1, v(X_3) = 1, v(X_4) = 1\)</span></li>
</ul>
<figure>
<img src="img/3SAT_VC_es1.png" title="3SAT vs. VC" alt="Riduzione della formula ad un ricoprimento" /><figcaption>Riduzione della formula ad un ricoprimento</figcaption>
</figure>
<ul>
<li><span class="math inline">\(v(X_1) = 1, v(X_2) = 0, v(X_3) = 1, v(X_4) = 0\)</span></li>
</ul>
<figure>
<img src="img/3SAT_VC_es2.png" title="3SAT vs. VC" alt="Riduzione della formula ad un ricoprimento" /><figcaption>Riduzione della formula ad un ricoprimento</figcaption>
</figure>
<h2 id="il-problema-dellinsieme-indipendente">Il Problema dell’insieme indipendente</h2>
<p>Ricordiamo che, dato un grafo <span class="math inline">\(G = (V , E)\)</span>, un insieme <span class="math inline">\(I \subseteq V\)</span> si dice <strong>indipendente</strong> se</p>
<p><span class="math display">\[∀u, v ∈ I \implies (u, v) \not \in E\]</span></p>
<blockquote>
<p>Il problema <span class="math inline">\(IS\)</span> di determinare se un grafo ammette un <strong>insieme indipendente</strong> <span class="math inline">\(I\)</span> di cardinalità <span class="math inline">\(|I| \ge k\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p>
</blockquote>
<p>Basta ricordare che <span class="math inline">\(I\)</span> è <strong>indipendente</strong> se e solo se <span class="math inline">\(V \setminus I\)</span> è un <strong>ricoprimento</strong>; poichè <span class="math inline">\(|I| \ge k\)</span> se e solo se <span class="math inline">\(|V \setminus I| \le |V| - k\)</span>, questo permette di ridurre <span class="math inline">\(IS\)</span> a <span class="math inline">\(VC\)</span>.</p>
<h2 id="il-problema-della-cricca">Il problema della Cricca</h2>
<p>Ricordiamo che, dato un grafo <span class="math inline">\(G = (V , E)\)</span>, una cricca di <span class="math inline">\(G\)</span> è un sottoinsieme <strong>completo</strong> <span class="math inline">\(C \subseteq V\)</span>, tale cioè che</p>
<p><span class="math display">\[\forall u, v \in C \implies (u, v) \in E\]</span></p>
<blockquote>
<p>Il problema <em>Clique</em> di determinare se un grafo <strong>ammette una cricca</strong> <span class="math inline">\(C\)</span> di cardinalità <span class="math inline">\(|C| \ge k\)</span> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p>
</blockquote>
<p>Ricordiamo che <span class="math inline">\(C\)</span> è una <strong>cricca</strong> in <span class="math inline">\(G\)</span> se e solo se <span class="math inline">\(C\)</span> è un <strong>insieme indipendente</strong> nel grafo <span class="math inline">\(G&#39; = (V , \overline{E})\)</span>.</p>
<p>Poichè <span class="math inline">\(G&#39;\)</span> può essere <strong>costruito in tempo</strong> lineare nella dimensione di <span class="math inline">\(G\)</span>, questo dimostra che <strong>Clique</strong> <span class="math inline">\(\le_{P} IS\)</span>.</p>
<h2 id="riduzione-da-sat-a-cammino-hamiltoniano-diretto">Riduzione da SAT a cammino Hamiltoniano diretto</h2>
<p>Supponiamo che il problema sia in <strong>forma di clausole</strong> <span class="math inline">\(C_1, \dots, C_m\)</span>.</p>
<p>Dobbiamo costruire un grafo <strong>diretto</strong> che ammette un cammino Hamiltoniano se e solo se l’insieme delle clausole è <strong>soddisfacibile</strong>.</p>
<p>Ad ogni variabile <span class="math inline">\(X\)</span> associamo una catena di <strong>lunghezza</strong> <span class="math inline">\(2m + 2\)</span> fatta nel modo seguente:</p>
<figure>
<img src="img/Catena_Ham_SAT.png" title="SAT vs. HAM" alt="Riduzione di SAT a HAM" /><figcaption>Riduzione di SAT a HAM</figcaption>
</figure>
<p>L’attraversamento della catena da <strong>sinistra verso destra</strong> o viceversa corrisponde ai possibili valori di verità di <span class="math inline">\(X\)</span>.</p>
<p>Le catene sono <strong>connesse</strong> tra di loro nel modo seguente:</p>
<figure>
<img src="img/Catene_Ham.png" title="Catene Hamiltoniane" alt="Riduzione di SAT a HAM" /><figcaption>Riduzione di SAT a HAM</figcaption>
</figure>
<p>I nodi corrispondenti alle <strong>clausole</strong> sono connessi alle catene nel modo seguente:</p>
<figure>
<img src="img/Catene_Ham_Nodi.png" title="Nodi corrispondenti alle clausole" alt="Riduzione di SAT a HAM" /><figcaption>Riduzione di SAT a HAM</figcaption>
</figure>
<p>In questo modo il vertice <strong>può essere attraversato</strong> solo se:</p>
<ul>
<li>la catena <span class="math inline">\(A\)</span> è attraversata in <strong>senso positivo</strong>,</li>
<li>oppure se la catena <span class="math inline">\(B\)</span> è attraversata in <strong>senso negativo</strong>,</li>
<li>oppure se la catena <span class="math inline">\(C\)</span> è attraversata in <strong>senso negativo</strong>.</li>
</ul>
<p>E’ facile convincersi che se una clausola è <strong>soddisfacibile</strong> allora il grafo <strong>ammette</strong> un cammino Hamiltoniano.</p>
<p>Il viceversa è <strong>meno ovvio</strong> e dipende dalla seguente osservazione:</p>
<p>se un cammino hamiltoniano esce da una catena sul nodo <span class="math inline">\(u\)</span> per andare verso una clausola <span class="math inline">\(c\)</span>, deve <strong>necessariamente rientrare subito</strong> nella stessa catena e sul nodo immediatamente <strong>adiacente</strong> <span class="math inline">\(u&#39;\)</span>.</p>
<p>In caso contrario il cammino sarebbe <strong>ostruito</strong> quando <span class="math inline">\(u&#39;\)</span> sarà visitato, in quanto gli <strong>unici nodi adiacenti</strong> sarebbero già stati <strong>tutti visitati</strong>.</p>
<h2 id="altri-esempi-di-problemi-np-completi">Altri esempi di problemi NP-completi</h2>
<ul>
<li><p><code>Problema del ciclo Hamiltoniano</code>: dato un grafo G, determinare se ammette un cammino Hamiltoniano.</p></li>
<li><p><code>Programmazione Intera</code>: data una <strong>matrice</strong> <span class="math inline">\(A \in Z^{n \times m}\)</span> e un <strong>vettore</strong> <span class="math inline">\(b \in Z^n\)</span>, determinare <strong>se esiste</strong> <span class="math inline">\(x \in Z^m\)</span> tale che <span class="math inline">\(Ax \ge b\)</span>.</p></li>
<li><p><code>Knapsack</code>: data una <strong>lista di interi</strong> <span class="math inline">\(a \in N^n\)</span> e un numero <span class="math inline">\(S \in N\)</span>, determinare se esiste <span class="math inline">\(I \subseteq \{ 1, 2, \dots, n \}\)</span> tale che <span class="math inline">\(\sum\limits_{i \in I}^n a_i = S\)</span>.</p></li>
<li><p><code>Equazioni Diofantee:</code> Il problema di decidere se un un polinomio di <strong>secondo grado</strong> a coefficienti <strong>interi</strong> ammette soluzioni <strong>intere</strong> è <strong><span class="math inline">\(NP\)</span>-completo</strong>.</p></li>
<li><code>lineare</code> <span class="math inline">\(\implies\)</span> <strong>polinomiale</strong> (Algoritmo di Euclide)</li>
<li><code>quadratica</code> <span class="math inline">\(\implies\)</span> <strong><span class="math inline">\(NP\)</span>-completo</strong> (Manders e Adleman)</li>
<li><p><code>arbitraria</code> <span class="math inline">\(\implies\)</span> <strong>indecidibile</strong> (Davis, Robinson, Matiyasevich)</p></li>
</ul>
<h1 id="complessità-relativizzata">Complessità relativizzata</h1>
<h2 id="macchine-ad-oracolo">Macchine ad oracolo</h2>
<p>Una Macchina di Turing non deterministica <strong>con oracolo</strong> è definita da un ennupla</p>
<p><span class="math display">\[M = (Q, q_0, q?, q+, q-, F, \Sigma, \Gamma, B, k, \delta)\]</span></p>
<p>con il significato inteso per le MdTN, <em>a parte le seguenti caratterisitche</em>:</p>
<ul>
<li><p><span class="math inline">\(M\)</span> è equipaggiata con un nastro particolare, detto <strong>nastro di interrogazione</strong>.</p></li>
<li><p><span class="math inline">\(M\)</span> ha tre stati <strong>speciali</strong> <span class="math inline">\(q?, q+, q- \in Q \setminus F\)</span> , dove <span class="math inline">\(q?\)</span> è lo stato di <strong>interrogazione</strong>, e <span class="math inline">\(q+\)</span>, <span class="math inline">\(q-\)</span> sono gli stati di <strong>risposta</strong>.</p></li>
<li><p>la funzione di <em>transizione</em> <span class="math inline">\(\delta\)</span> <strong>non è definita</strong> sullo stato di <strong>interrogazione</strong>.</p></li>
</ul>
<h2 id="semantica-delle-mdtn-ad-oracolo">Semantica delle MdTN ad oracolo</h2>
<p>La nozione di <strong>computazione</strong> è definita nel modo abituale, ad eccezione delle regole seguenti:</p>
<ul>
<li><p>la macchina può <strong>scrivere</strong> sul nastro di <em>interrogazione</em> come su di un nastro <strong>abituale</strong>,</p></li>
<li><p>nel momento in cui la macchina <strong>entra</strong> nello stato di <em>interrograzione</em> <span class="math inline">\(q?\)</span> lo stato successivo non è determinato dalla funzione <span class="math inline">\(\delta\)</span> ma da un <strong>oracolo esterno <span class="math inline">\(O\)</span></strong>. In particolare se nello stato <span class="math inline">\(q?\)</span> il nastro di <strong>interrogazione</strong> contiene la parola <span class="math inline">\(y \in \Sigma^*\)</span> <strong>alla sinistra</strong> della testina, allora lo stato successivo della macchina è <span class="math inline">\(q+\)</span> se <span class="math inline">\(y \in O\)</span> e <span class="math inline">\(q-\)</span> se <span class="math inline">\(y \not \in O\)</span>,</p></li>
<li><p>Il <strong>contenuto</strong> del nastro di interrogazione è <strong>cancellato</strong> automaticamente non appena la macchina <strong>rientra</strong> nello stato <span class="math inline">\(q+\)</span> o <span class="math inline">\(q-\)</span>.</p></li>
</ul>
<p>Denotiamo con <span class="math inline">\(L_O(f_M)\)</span> il linguaggio <strong>accettato</strong> (<em>la funzione calcolata</em>) dalla macchina <span class="math inline">\(M\)</span> con oracolo <span class="math inline">\(O\)</span>.</p>
<h2 id="tempo-e-spazio-per-mdtn-ad-oracolo">Tempo e Spazio per MdTN ad oracolo</h2>
<p>Sia <span class="math inline">\(M\)</span> una MdTN con oracolo <span class="math inline">\(A\)</span>:</p>
<ul>
<li><p><span class="math inline">\(time_M^A(x)\)</span> è definito come nel caso deterministico, dove la transizione dallo stato di <em>interrogazione</em> a quello di <em>risposta</em> ha costo <strong>unitario</strong>,</p></li>
<li><p><span class="math inline">\(t_M^A(n)\)</span> è il <strong>massimo</strong> <span class="math inline">\(time_M^A(x)\)</span> al variare di <span class="math inline">\(x\)</span> su tutti le stringhe di lunghezza <span class="math inline">\(|x| = n\)</span>,</p></li>
<li><p><span class="math inline">\(t_M(n)\)</span> è massimo <span class="math inline">\(t_M^A(n)\)</span> per <span class="math inline">\(A \subseteq \Sigma^*\)</span>.</p></li>
</ul>
<p><span class="math inline">\(space_M^A(n)\)</span>, <span class="math inline">\(s_M^A(n)\)</span> e <span class="math inline">\(s_M(n)\)</span> sono definite in modo <strong>analogo</strong> (lo spazio richiesto per la scrittura sul nastro di interrogazione è <strong>rilevante</strong>).</p>
<h2 id="classi-di-complessità-con-oracolo">Classi di complessità con oracolo</h2>
<p>Sia <span class="math inline">\(C\)</span> una <strong>classe</strong> di complessità e sia <span class="math inline">\(O \subset \Sigma^*\)</span> un <strong>oracolo</strong>.</p>
<p>La classe <span class="math inline">\(C^O\)</span> è definita in modo analogo a <span class="math inline">\(C\)</span> con la differenza che si considerano macchine con oracolo <span class="math inline">\(O\)</span> invece delle macchine abituali.</p>
<p>Ad esempio <span class="math inline">\(P^{SAT}\)</span> è l’insieme dei <strong>linguaggi</strong> che ammettono un algoritmo di <strong>decisione polinomiale</strong>, <strong>ammesso</strong> di avere un oracolo per <span class="math inline">\(SAT\)</span>.</p>
<p>Se inoltre <span class="math inline">\(C&#39;\)</span> è una classe di complessità, allora</p>
<p><span class="math display">\[C^{C&#39;} \coloneqq \bigcup_{O \in C&#39;} C^O\]</span></p>
<p>ovvero è la classe dei problemi che hanno <strong>complessità</strong> <span class="math inline">\(C\)</span> ammesso di avere un <strong>opportuno oracolo</strong> di complessità <span class="math inline">\(C&#39;\)</span>.</p>
<p>Ad esempio <span class="math inline">\(NP^{PSPACE}\)</span> è l’insieme dei linguaggi <strong>riconoscibili</strong> in tempo <strong>polinomiale non deterministico</strong> mediante una qualche macchina che utilizza un <strong>oracolo</strong> relativo ad un problema in <span class="math inline">\(PSPACE\)</span>.</p>
<p>Per tutti i linguaggi <span class="math inline">\(A, B, C \in \Sigma^*\)</span></p>
<ul>
<li><p><span class="math inline">\(A \in P^A\)</span>, ovvio perchè <span class="math inline">\(P^A\)</span> è la classe dei problemi che hanno complessità <span class="math inline">\(P\)</span> ammesso di avere un oppurtuno oracolo di complessità <span class="math inline">\(A\)</span>.</p></li>
<li><p><span class="math inline">\(A \in P^B \implies A \in NP^B\)</span>, perchè le <em>MdT</em> sono un caso particolare di <em>MdTN</em>.</p></li>
<li><p><span class="math inline">\(A \in NP^B \implies A \in NP^{\Sigma^* \setminus B}\)</span>, <span class="math inline">\(\Sigma^* \setminus B\)</span> è uguale a <span class="math inline">\(\overline{B}\)</span>, avere un oracolo per <span class="math inline">\(\overline{B}\)</span> è come avere l’oracolo <span class="math inline">\(B\)</span>.</p></li>
<li><p><span class="math inline">\(A \in P^B, B \in P^C \implies A \in P^C\)</span>, grazie alla chiusura per <strong>composizione</strong>.</p></li>
<li><p><span class="math inline">\(A \in NP^B, B \in P^C \implies A \in NP^C\)</span>, sempre per composizione perchè una macchina <span class="math inline">\(ND\)</span> può “inglobarne” una <span class="math inline">\(D\)</span>, ma non sappiamo fare il <strong>viceversa</strong></p></li>
</ul>
<blockquote>
<p><strong>N.B</strong> <span class="math inline">\(A \in NP^B, B \in NP^C \nRightarrow A \in NP^C\)</span></p>
</blockquote>
<h2 id="alcune-classi-di-complessità-con-oracolo">Alcune Classi di Complessità con oracolo</h2>
<ol type="1">
<li><p><span class="math inline">\(P^P = P\)</span></p>
<p><span class="math inline">\(P \subseteq P^P\)</span> poichè <span class="math inline">\(A \in P^P\)</span>; <span class="math inline">\(P^P \subseteq P\)</span> segue da</p>
<p><span class="math inline">\(A \in P^B, B \in P^C \implies A \in P^C\)</span> con <span class="math inline">\(C = \emptyset\)</span></p></li>
<li><p><span class="math inline">\(NP^P = NP\)</span></p>
<p>Analoga alla precedente</p></li>
<li><p><span class="math inline">\(NP^{PSPACE} = PSPACE\)</span></p>
<p><span class="math inline">\(PSPACE \subseteq NP^{PSPACE}\)</span> poichè <span class="math inline">\(A \in NP^A\)</span>.</p></li>
</ol>
<p><span class="math inline">\(NP^{PSPACE} \subseteq PSPACE\)</span> si ottiene modificando al caso <strong>con oracolo</strong> la dimostrazione che <span class="math inline">\(NTIME(f) \subseteq DSPACE(f)\)</span>.</p>
<h3 id="nppspace-subseteq-pspace"><span class="math inline">\(NP^{PSPACE} \subseteq PSPACE\)</span></h3>
<p>Supponiamo che <span class="math inline">\(M\)</span> sia un MdTN con <strong>oracolo</strong> <span class="math inline">\(A \in PSPACE\)</span> e che <span class="math inline">\(t_M \le p\)</span> per qualche <strong>polinomio</strong> <span class="math inline">\(p\)</span>.</p>
<p>Otteniamo una macchina deterministica <span class="math inline">\(M&#39;\)</span> <strong>eliminando il nondeterminismo</strong> con la tecnica utilizzata nella dimostrazione che <span class="math inline">\(NTIME (f) \le DSPACE (f)\)</span> (ovvero <strong>esplorando esaustivamente</strong> l’albero delle computazioni di <span class="math inline">\(M\)</span>).</p>
<p>Abbiamo che <span class="math inline">\(L_{M&#39;}^A = L_M^A\)</span> e <span class="math inline">\(s_{M&#39;}^A \in O(p)\)</span>.</p>
<p>Poichè <strong>ogni interrogazione</strong> <span class="math inline">\(y \in A\)</span> posta dalla macchina <span class="math inline">\(M(M&#39;)\)</span> su input <span class="math inline">\(x\)</span> ha lunghezza <span class="math inline">\(|y| \le p(|x|)\)</span> e <span class="math inline">\(A \in PSPACE\)</span>, possiamo <strong>rimpiazzare</strong> l’oracolo con un <em>sottoprogramma</em> per <span class="math inline">\(A\)</span> utilizzando una qualche MdT <span class="math inline">\(M&#39;&#39;\)</span> tale che <span class="math inline">\(L_{M&#39;&#39;} = A\)</span> e <span class="math inline">\(s_{M&#39;&#39;} \le q\)</span> per un qualche polinomio <span class="math inline">\(q\)</span>.</p>
<p>La macchina risultante <span class="math inline">\(M&#39;&#39;&#39;\)</span> è <strong>deterministica</strong>, <span class="math inline">\(L_{M&#39;&#39;&#39;} = L_{M&#39;}^A = L_{M}^A\)</span> e <span class="math inline">\(s_{M&#39;&#39;&#39;} \in O(pq)\)</span>.</p>
<p>Dunque, <span class="math inline">\(L_{M}^A \in PSPACE\)</span>.</p>
<h3 id="lemma-np-subseteq-pnp-subseteq-npnp">Lemma: <span class="math inline">\(NP \subseteq P^{NP} \subseteq NP^{NP}\)</span></h3>
<blockquote>
<p><span class="math display">\[NP^P = NP \subseteq P^{NP} \subseteq NP^{NP}\]</span></p>
</blockquote>
<p>Abbiamo già dimostrato la prima uguaglianza.</p>
<ul>
<li><span class="math inline">\(NP \subseteq P^{NP}\)</span> segue dal fatto che <span class="math inline">\(A \in P^{A}\)</span>.</li>
<li><span class="math inline">\(P^{NP} \subseteq NP^{NP}\)</span> segue dal fatto che <span class="math inline">\(A \in P^B \implies A \in NP^B\)</span>.</li>
</ul>
<h2 id="np-e-conp"><span class="math inline">\(NP\)</span> e <strong>co<span class="math inline">\(NP\)</span></strong></h2>
<blockquote>
<p><span class="math display">\[NP^{NP} = NP \iff NP = coNP\]</span></p>
</blockquote>
<p><strong>Dimostriamo che <span class="math inline">\(NP = coNP \implies NP^{NP} = NP\)</span>.</strong></p>
<p>Sappiamo che <span class="math inline">\(NP \subseteq NP^{NP}\)</span>; dobbiamo quindi dimostrare che <span class="math inline">\(NP^{NP} \subseteq NP\)</span>.</p>
<p>Sia data una MdTN <span class="math inline">\(M\)</span> che opera in tempo <span class="math inline">\(t_M \in O(q)\)</span> per qualche polinomio <span class="math inline">\(q\)</span> e un qualche oracolo <span class="math inline">\(A \in NP\)</span>.</p>
<p>Siccome <span class="math inline">\(A \in NP = coNP\)</span>, esistono due MdTN <span class="math inline">\(M+\)</span> e <span class="math inline">\(M-\)</span> tali che <span class="math inline">\(M+\)</span> <strong>accetta</strong> <span class="math inline">\(A\)</span> e <span class="math inline">\(M-\)</span> <strong>accetta</strong> <span class="math inline">\(A\)</span>, entrambe in <strong>tempo</strong> polinomiale <span class="math inline">\(p\)</span>.</p>
<p>Possiamo allora costruire una <strong>nuova</strong> <em>MdTN</em> <span class="math inline">\(M&#39;\)</span> che opera nel modo seguente: <strong>ogni interrogazione</strong> <span class="math inline">\(y \in A\)</span> di <span class="math inline">\(M\)</span> è rimpiazzata da una <strong>chiamata simultanea</strong> a <span class="math inline">\(M+\)</span> e <span class="math inline">\(M-\)</span> su input <span class="math inline">\(y\)</span>.</p>
<p>Se una delle due macchine <span class="math inline">\(M+\)</span> o <span class="math inline">\(M-\)</span> termina con <strong>accettazione</strong>, allora si <em>entra</em> rispettivamente nello stato <span class="math inline">\(q+\)</span> o <span class="math inline">\(q-\)</span> e si riprende la simulazione di <span class="math inline">\(M\)</span>.</p>
<p>La macchina <span class="math inline">\(M&#39;\)</span> riconosce <span class="math inline">\(L_M\)</span> in tempo <span class="math inline">\(O(qp)\)</span>.</p>
<p><strong>Mostriamo ora che <span class="math inline">\(NP^{NP} = NP \implies NP = coNP\)</span>.</strong></p>
<p>Ricordiamo innanzitutto che per ogni <span class="math inline">\(A\)</span></p>
<p><span class="math display">\[NP^A = NP^{\overline{A}}\]</span></p>
<p>Abbiamo allora le seguenti proprietà:</p>
<ul>
<li><p>se <span class="math inline">\(A \in coNP\)</span>, allora <span class="math inline">\(\overline{A} \in NP\)</span> e dunque</p>
<p><span class="math display">\[A \in NP^A\]</span> <span class="math display">\[NP^A = NP^{\overline{A}}\]</span> <span class="math display">\[NP^{\overline{A}} \subseteq NP^{NP} = NP\]</span></p>
<p>che dimostra che <span class="math inline">\(coNP \subseteq NP\)</span></p></li>
<li><p>se <span class="math inline">\(A \in NP\)</span>, allora</p>
<p><span class="math display">\[A \in NP^{\overline{A}}\]</span> <span class="math display">\[NP^{\overline{A}} = NP^A\]</span> <span class="math display">\[NP^A \subseteq NP^{NP} = NP\]</span></p>
<p>e dunque <span class="math inline">\(A \in coNP\)</span>, che dimostra che <span class="math inline">\(NP \subseteq coNP\)</span>.</p></li>
</ul>
<h1 id="la-gerarchia-polinomiale">La gerarchia polinomiale</h1>
<p>Per <span class="math inline">\(n \in N\)</span> si definiscono le seguenti classi:</p>
<ul>
<li><span class="math inline">\(\Sigma_0^P \coloneqq \Pi_0^P \coloneqq \Delta_0^P \coloneqq P\)</span></li>
<li><span class="math inline">\(\Sigma_{n+1}^P \coloneqq NP^{\Sigma_n^P}\)</span></li>
<li><span class="math inline">\(\Pi_{n+1}^P \coloneqq co\Sigma_{n+1}^P\)</span></li>
<li><span class="math inline">\(\Delta_{n+1}^P \coloneqq P^{\Sigma_n^P}\)</span></li>
</ul>
<p>La classe</p>
<p><span class="math display">\[PH \coloneqq \bigcup_{n \in N} \Sigma_n^P\]</span></p>
<p>è detta <strong>gerarchia polinomiale</strong>.</p>
<p>Osservazioni:</p>
<ul>
<li><span class="math inline">\(\Sigma_1^P = NP^P = NP\)</span>, <span class="math inline">\(\Sigma_2^P = NP^{NP}\)</span>, <span class="math inline">\(\Sigma_3^P = NP^{NP^{NP}}\)</span>, <span class="math inline">\(\dots\)</span></li>
<li><span class="math inline">\(\Delta_1^P = P^P = P\)</span>, <span class="math inline">\(\Delta_2^P = P^{NP}\)</span>, <span class="math inline">\(\Delta_3^P = P^{NP^{NP}}\)</span>, <span class="math inline">\(\dots\)</span></li>
<li>se <span class="math inline">\(P = NP\)</span>, allora <span class="math inline">\(PH = P\)</span>,</li>
<li>se <span class="math inline">\(coNP = NP\)</span>, allora <span class="math inline">\(PH = NP\)</span>.</li>
</ul>
<h2 id="teorema-della-gerarchia-polinomiale">Teorema della gerarchia polinomiale</h2>
<blockquote>
<p>Per ogni <span class="math inline">\(n \in N\)</span> valgono le seguenti inclusioni:</p>
<p><span class="math display">\[\Sigma_n^P \cup \Pi_n^P \subseteq \Delta_{n+1}^P \subseteq \Sigma_{n+1}^P \cap \Pi_{n+1}^P \subseteq PSPACE\]</span></p>
</blockquote>
<p>La dimostrazione è una conseguenza delle seguenti osservazioni:</p>
<ul>
<li><p><span class="math inline">\(A \in P^A \implies \Sigma_n^P \subseteq P^{\Sigma_n^P} = \Delta_{n+1}^P\)</span></p></li>
<li><p><span class="math inline">\(A \in P^A = P^{\overline{P}} \implies \Pi_n^P \subseteq P^{\Pi_n^P} = P^{\Sigma_n^P} = \Delta_{n+1}^P\)</span></p></li>
<li><p><span class="math inline">\(P^A \subseteq NP^A \implies \Delta_{n+1}^P = P^{\Sigma_n^P} \subseteq NP^{\Sigma_n^P} = \Sigma_{n+1}^P\)</span></p></li>
<li><p><span class="math inline">\(\Delta_{n+1}^P = P^{\Sigma_n^P} = coP^{\Sigma_n^P} \subseteq coNP^{\Sigma_n^P} = \Pi_{n+1}^P\)</span></p></li>
<li><p><span class="math inline">\(\Sigma_0^P = P \subseteq PSPACE\)</span></p></li>
<li><p><span class="math inline">\(NP^{PSPACE} = PSPACE \implies \Sigma_{n+1}^P = NP^{\Sigma_n^P} \subseteq PSPACE\)</span></p></li>
</ul>
</body>
</html>
